{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Heart Disease: EDA + 3-Model Ensemble + W&B Tracking\n",
    "\n",
    "**Competition:** [Playground Series S6E2](https://www.kaggle.com/competitions/playground-series-s6e2)  \n",
    "**Task:** Binary classification (Heart Disease: Presence / Absence)  \n",
    "**Metric:** AUC-ROC  \n",
    "\n",
    "---\n",
    "\n",
    "## What's in this notebook?\n",
    "\n",
    "| Section | Content |\n",
    "|---|---|\n",
    "| **1. Data Overview** | Shape, types, missing values, target balance |\n",
    "| **2. EDA** | Distribution analysis, feature-target relationships, correlation |\n",
    "| **3. Feature Engineering** | Interaction features, domain-inspired transforms |\n",
    "| **4. Modeling** | LightGBM, XGBoost, CatBoost with 5-fold CV |\n",
    "| **5. W&B Experiment Tracking** | All runs logged to Weights & Biases for comparison |\n",
    "| **6. Ensemble & Submission** | Simple average of 3 models |\n",
    "\n",
    "If you find this useful, please **upvote**! It helps a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install -q --upgrade wandb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import wandb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "COLORS = {'no': '#2ecc71', 'yes': '#e74c3c', 'accent': '#3498db'}\n",
    "\n",
    "print('All libraries loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# W&B login via Kaggle Secrets\n# To use W&B: Add your API key in Kaggle > Add-ons > Secrets > Label: WANDB_API_KEY\nUSE_WANDB = False\n\n# Step 1: Get API key from Kaggle Secrets\nwandb_api_key = None\ntry:\n    from kaggle_secrets import UserSecretsClient\n    print('Step 1a: kaggle_secrets imported OK')\n    secrets = UserSecretsClient()\n    print('Step 1b: UserSecretsClient created OK')\n    wandb_api_key = secrets.get_secret('WANDB_API_KEY')\n    print(f'Step 1c: Secret retrieved OK (length={len(wandb_api_key) if wandb_api_key else 0})')\nexcept Exception as e:\n    print(f'Step 1 FAILED: {type(e).__name__}: {e}')\n\n# Step 2: Login to W&B\nif wandb_api_key:\n    try:\n        wandb.login(key=wandb_api_key)\n        USE_WANDB = True\n        print('Step 2: W&B logged in successfully!')\n    except Exception as e:\n        print(f'Step 2 FAILED: {type(e).__name__}: {e}')\nelse:\n    print('No API key available. Running without W&B.')\n\nprint(f'\\nUSE_WANDB = {USE_WANDB}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/playground-series-s6e2/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s6e2/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/playground-series-s6e2/sample_submission.csv')\n",
    "\n",
    "print(f'Train shape: {train.shape}')\n",
    "print(f'Test shape:  {test.shape}')\n",
    "print(f'\\nColumn names:')\n",
    "for i, col in enumerate(train.columns):\n",
    "    print(f'  {i:2d}. {col:30s} {train[col].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify target and feature columns\n",
    "TARGET = 'Heart Disease'\n",
    "ID = 'id'\n",
    "\n",
    "print(f'Target column: \"{TARGET}\"')\n",
    "print(f'Target unique values: {train[TARGET].unique()}')\n",
    "print(f'Target value counts:')\n",
    "print(train[TARGET].value_counts())\n",
    "\n",
    "# Submission column check\n",
    "print(f'\\nSubmission columns: {submission.columns.tolist()}')\n",
    "print(f'Submission head:\\n{submission.head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values check\n",
    "missing_train = train.isnull().sum()\n",
    "missing_test = test.isnull().sum()\n",
    "missing_df = pd.DataFrame({'train': missing_train, 'test': missing_test})\n",
    "print('Missing values:')\n",
    "print(missing_df[missing_df.sum(axis=1) > 0] if missing_df.sum().sum() > 0 else 'No missing values!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. EDA\n",
    "\n",
    "### 2.1 Target Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target for analysis: Presence=1, Absence=0\n",
    "target_map = {'Absence': 0, 'Presence': 1}\n",
    "# Auto-detect target mapping\n",
    "unique_vals = train[TARGET].unique()\n",
    "print(f'Target unique values: {unique_vals}')\n",
    "\n",
    "# Try to create binary target\n",
    "if set(unique_vals) == {'Absence', 'Presence'}:\n",
    "    train['target'] = train[TARGET].map(target_map)\n",
    "elif train[TARGET].dtype in ['int64', 'float64']:\n",
    "    train['target'] = train[TARGET]\n",
    "else:\n",
    "    le_target = LabelEncoder()\n",
    "    train['target'] = le_target.fit_transform(train[TARGET])\n",
    "    print(f'Label mapping: {dict(zip(le_target.classes_, le_target.transform(le_target.classes_)))}')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Count\n",
    "counts = train[TARGET].value_counts()\n",
    "axes[0].bar(counts.index, counts.values, \n",
    "            color=[COLORS['no'], COLORS['yes']])\n",
    "axes[0].set_title('Target Count')\n",
    "for i, v in enumerate(counts.values):\n",
    "    axes[0].text(i, v + v*0.01, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Proportion\n",
    "props = train[TARGET].value_counts(normalize=True)\n",
    "axes[1].pie(props.values, labels=props.index, \n",
    "            colors=[COLORS['no'], COLORS['yes']],\n",
    "            autopct='%1.1f%%', startangle=90, textprops={'fontsize': 12})\n",
    "axes[1].set_title('Target Proportion')\n",
    "\n",
    "plt.suptitle('Target Distribution', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Feature Distributions by Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in train.columns if c not in [ID, TARGET, 'target']]\n",
    "n_features = len(feature_cols)\n",
    "n_rows = (n_features + 2) // 3\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, 3, figsize=(16, 4 * n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(feature_cols):\n",
    "    ax = axes[i]\n",
    "    for label, color, name in [(0, COLORS['no'], 'No Disease'), (1, COLORS['yes'], 'Disease')]:\n",
    "        data = train[train['target'] == label][col]\n",
    "        ax.hist(data, alpha=0.6, label=name, bins=30, color=color, edgecolor='white')\n",
    "    ax.set_title(col, fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Hide empty subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.suptitle('Feature Distributions by Heart Disease Status', fontsize=14, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with numeric target\n",
    "corr_df = train[feature_cols + ['target']].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_df, dtype=bool))\n",
    "sns.heatmap(corr_df, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r', center=0,\n",
    "            ax=ax, square=True, linewidths=0.5, cbar_kws={'shrink': 0.8})\n",
    "ax.set_title('Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top correlations with target\n",
    "target_corr = corr_df['target'].drop('target').abs().sort_values(ascending=False)\n",
    "print('\\nTop correlations with Heart Disease (absolute):')\n",
    "for feat, val in target_corr.items():\n",
    "    direction = '+' if corr_df.loc[feat, 'target'] > 0 else '-'\n",
    "    print(f'  {feat:30s} {direction}{val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Feature Stats by Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean values comparison\n",
    "comparison = train.groupby('target')[feature_cols].mean().T\n",
    "comparison.columns = ['No Disease (0)', 'Disease (1)']\n",
    "comparison['Diff %'] = ((comparison['Disease (1)'] - comparison['No Disease (0)']) / comparison['No Disease (0)'] * 100).round(1)\n",
    "comparison = comparison.round(2)\n",
    "print('Feature means by target:')\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train + test\n",
    "train_len = len(train)\n",
    "df = pd.concat([train.drop(['target'], axis=1), test], axis=0, ignore_index=True)\n",
    "\n",
    "# Encode target\n",
    "le_target = LabelEncoder()\n",
    "df.loc[:train_len-1, 'target_encoded'] = le_target.fit_transform(df.loc[:train_len-1, TARGET])\n",
    "\n",
    "# Interaction features\n",
    "df['Age_x_MaxHR'] = df['Age'] * df['Max HR']\n",
    "df['Age_x_STdep'] = df['Age'] * df['ST depression']\n",
    "df['STdep_x_Slope'] = df['ST depression'] * df['Slope of ST']\n",
    "df['BP_x_Chol'] = df['BP'] * df['Cholesterol']\n",
    "df['MaxHR_div_Age'] = df['Max HR'] / (df['Age'] + 1)\n",
    "df['Vessels_x_Thal'] = df['Number of vessels fluro'] * df['Thallium']\n",
    "\n",
    "# All feature columns for model\n",
    "model_features = [c for c in df.columns if c not in [ID, TARGET, 'target_encoded']]\n",
    "\n",
    "# Split back\n",
    "X = df.iloc[:train_len][model_features].values\n",
    "y = df.iloc[:train_len]['target_encoded'].values.astype(int)\n",
    "X_test = df.iloc[train_len:][model_features].values\n",
    "\n",
    "print(f'Features ({len(model_features)}):')\n",
    "for f in model_features:\n",
    "    print(f'  - {f}')\n",
    "print(f'\\nX shape: {X.shape}, y shape: {y.shape}, X_test shape: {X_test.shape}')\n",
    "print(f'Target: 0={le_target.classes_[0]}, 1={le_target.classes_[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Modeling with W&B Experiment Tracking\n",
    "\n",
    "We train 3 gradient boosting models with **5-fold Stratified CV** and log everything to **Weights & Biases** for easy comparison.\n",
    "\n",
    "> **Why W&B?** It automatically tracks hyperparameters, metrics, and makes it easy to compare experiments across different runs. [wandb.ai](https://wandb.ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "SEED = 42\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "def wandb_init(name, tags, config):\n",
    "    if USE_WANDB:\n",
    "        return wandb.init(\n",
    "            project='kaggle-s6e2-heart-disease',\n",
    "            name=name, tags=tags, config=config, reinit=True\n",
    "        )\n",
    "    return None\n",
    "\n",
    "def wandb_log(data):\n",
    "    if USE_WANDB:\n",
    "        wandb.log(data)\n",
    "\n",
    "def wandb_end():\n",
    "    if USE_WANDB:\n",
    "        wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "lgb_params = {\n    'objective': 'binary',\n    'metric': 'auc',\n    'verbosity': -1,\n    'n_estimators': 1000,\n    'learning_rate': 0.05,\n    'max_depth': 6,\n    'num_leaves': 31,\n    'min_child_samples': 20,\n    'subsample': 0.8,\n    'colsample_bytree': 0.8,\n    'random_state': SEED,\n    'device': 'gpu',\n}\n\nwandb_init('lgb-baseline', ['lightgbm', 'baseline', 'gpu'], {'model': 'LightGBM', **lgb_params})\n\nlgb_oof = np.zeros(len(X))\nlgb_preds = np.zeros(len(X_test))\nlgb_importances = np.zeros(len(model_features))\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n    model = lgb.LGBMClassifier(**lgb_params)\n    model.fit(\n        X[train_idx], y[train_idx],\n        eval_set=[(X[val_idx], y[val_idx])],\n        callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n    )\n    lgb_oof[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n    lgb_preds += model.predict_proba(X_test)[:, 1] / N_SPLITS\n    lgb_importances += model.feature_importances_ / N_SPLITS\n    \n    fold_auc = roc_auc_score(y[val_idx], lgb_oof[val_idx])\n    wandb_log({'fold': fold, 'fold_auc': fold_auc})\n    print(f'  Fold {fold}: AUC = {fold_auc:.5f}')\n\nlgb_auc = roc_auc_score(y, lgb_oof)\nprint(f'  >>> LightGBM CV AUC: {lgb_auc:.5f}')\nwandb_log({'cv_auc': lgb_auc})\nwandb_end()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "xgb_params = {\n    'objective': 'binary:logistic',\n    'eval_metric': 'auc',\n    'n_estimators': 1000,\n    'learning_rate': 0.05,\n    'max_depth': 6,\n    'subsample': 0.8,\n    'colsample_bytree': 0.8,\n    'random_state': SEED,\n    'verbosity': 0,\n    'early_stopping_rounds': 50,\n    'tree_method': 'hist',\n    'device': 'cuda',\n}\n\nwandb_init('xgb-baseline', ['xgboost', 'baseline', 'gpu'], {'model': 'XGBoost', **xgb_params})\n\nxgb_oof = np.zeros(len(X))\nxgb_preds = np.zeros(len(X_test))\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n    model = xgb.XGBClassifier(**xgb_params)\n    model.fit(\n        X[train_idx], y[train_idx],\n        eval_set=[(X[val_idx], y[val_idx])],\n        verbose=False\n    )\n    xgb_oof[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n    xgb_preds += model.predict_proba(X_test)[:, 1] / N_SPLITS\n    \n    fold_auc = roc_auc_score(y[val_idx], xgb_oof[val_idx])\n    wandb_log({'fold': fold, 'fold_auc': fold_auc})\n    print(f'  Fold {fold}: AUC = {fold_auc:.5f}')\n\nxgb_auc = roc_auc_score(y, xgb_oof)\nprint(f'  >>> XGBoost CV AUC: {xgb_auc:.5f}')\nwandb_log({'cv_auc': xgb_auc})\nwandb_end()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "cat_params = {\n    'iterations': 1000,\n    'learning_rate': 0.05,\n    'depth': 6,\n    'eval_metric': 'AUC',\n    'random_seed': SEED,\n    'verbose': 0,\n    'early_stopping_rounds': 50,\n    'task_type': 'GPU',\n}\n\nwandb_init('cat-baseline', ['catboost', 'baseline', 'gpu'], {'model': 'CatBoost', **cat_params})\n\ncat_oof = np.zeros(len(X))\ncat_preds = np.zeros(len(X_test))\n\nfor fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n    model = CatBoostClassifier(**cat_params)\n    model.fit(\n        X[train_idx], y[train_idx],\n        eval_set=(X[val_idx], y[val_idx]),\n    )\n    cat_oof[val_idx] = model.predict_proba(X[val_idx])[:, 1]\n    cat_preds += model.predict_proba(X_test)[:, 1] / N_SPLITS\n    \n    fold_auc = roc_auc_score(y[val_idx], cat_oof[val_idx])\n    wandb_log({'fold': fold, 'fold_auc': fold_auc})\n    print(f'  Fold {fold}: AUC = {fold_auc:.5f}')\n\ncat_auc = roc_auc_score(y, cat_oof)\nprint(f'  >>> CatBoost CV AUC: {cat_auc:.5f}')\nwandb_log({'cv_auc': cat_auc})\nwandb_end()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble\n",
    "ens_oof = (lgb_oof + xgb_oof + cat_oof) / 3\n",
    "ens_preds = (lgb_preds + xgb_preds + cat_preds) / 3\n",
    "ens_auc = roc_auc_score(y, ens_oof)\n",
    "\n",
    "# Log ensemble to W&B\n",
    "wandb_init('ensemble-avg', ['ensemble'], {\n",
    "    'method': 'simple_average',\n",
    "    'models': ['LightGBM', 'XGBoost', 'CatBoost']\n",
    "})\n",
    "wandb_log({\n",
    "    'lgb_auc': lgb_auc, 'xgb_auc': xgb_auc,\n",
    "    'cat_auc': cat_auc, 'ensemble_auc': ens_auc\n",
    "})\n",
    "wandb_end()\n",
    "\n",
    "# Results table\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['LightGBM', 'XGBoost', 'CatBoost', 'Ensemble (avg)'],\n",
    "    'CV AUC': [lgb_auc, xgb_auc, cat_auc, ens_auc]\n",
    "}).sort_values('CV AUC', ascending=False)\n",
    "\n",
    "print('=' * 40)\n",
    "print('      MODEL COMPARISON')\n",
    "print('=' * 40)\n",
    "for _, row in results.iterrows():\n",
    "    marker = ' <<<' if row['Model'] == 'Ensemble (avg)' else ''\n",
    "    print(f\"  {row['Model']:20s} AUC: {row['CV AUC']:.5f}{marker}\")\n",
    "print('=' * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for name, oof, color in [\n",
    "    ('LightGBM', lgb_oof, '#e67e22'),\n",
    "    ('XGBoost', xgb_oof, '#9b59b6'),\n",
    "    ('CatBoost', cat_oof, '#1abc9c'),\n",
    "    ('Ensemble', ens_oof, '#e74c3c'),\n",
    "]:\n",
    "    fpr, tpr, _ = roc_curve(y, oof)\n",
    "    auc_val = roc_auc_score(y, oof)\n",
    "    lw = 3 if name == 'Ensemble' else 1.5\n",
    "    axes[0].plot(fpr, tpr, label=f'{name} (AUC={auc_val:.4f})', linewidth=lw, color=color)\n",
    "\n",
    "axes[0].plot([0, 1], [0, 1], 'k--', alpha=0.3)\n",
    "axes[0].set_xlabel('False Positive Rate')\n",
    "axes[0].set_ylabel('True Positive Rate')\n",
    "axes[0].set_title('ROC Curves', fontweight='bold')\n",
    "axes[0].legend(fontsize=10)\n",
    "\n",
    "# Feature importance (LightGBM)\n",
    "imp = pd.Series(lgb_importances, index=model_features).sort_values(ascending=True)\n",
    "imp.plot(kind='barh', ax=axes[1], color=COLORS['accent'])\n",
    "axes[1].set_title('Feature Importance (LightGBM avg)', fontweight='bold')\n",
    "axes[1].set_xlabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.hist(ens_oof[y == 0], bins=50, alpha=0.6, label='No Disease (actual)', color=COLORS['no'], edgecolor='white')\n",
    "ax.hist(ens_oof[y == 1], bins=50, alpha=0.6, label='Disease (actual)', color=COLORS['yes'], edgecolor='white')\n",
    "ax.axvline(0.5, color='black', linestyle='--', alpha=0.5, label='Threshold=0.5')\n",
    "ax.set_xlabel('Predicted Probability')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Ensemble OOF Prediction Distribution', fontweight='bold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check submission format\n",
    "print(f'Submission columns: {submission.columns.tolist()}')\n",
    "print(f'Expected target column: \"{TARGET}\"')\n",
    "\n",
    "submission[TARGET] = ens_preds\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(f'\\nSubmission shape: {submission.shape}')\n",
    "print(f'Prediction range: [{ens_preds.min():.4f}, {ens_preds.max():.4f}]')\n",
    "print(f'Prediction mean:  {ens_preds.mean():.4f}')\n",
    "submission.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| What | Detail |\n",
    "|---|---|\n",
    "| **Models** | LightGBM + XGBoost + CatBoost |\n",
    "| **Ensemble** | Simple average of 3 models |\n",
    "| **CV** | 5-fold Stratified |\n",
    "| **Feature engineering** | 6 interaction features (Age*MaxHR, STdep*Slope, etc.) |\n",
    "| **Experiment tracking** | W&B (optional, via Kaggle Secrets) |\n",
    "\n",
    "### Possible improvements\n",
    "- Optuna hyperparameter tuning (logged to W&B)\n",
    "- Add original dataset as extra training data\n",
    "- Rank-based ensemble instead of simple average\n",
    "- Target encoding for low-cardinality integer features\n",
    "- Multi-seed averaging for stability\n",
    "\n",
    "---\n",
    "\n",
    "If this notebook was helpful, please consider giving it an **upvote**! Thank you for reading."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}