Kaggleã€Œä½å®…ä¾¡æ ¼äºˆæ¸¬ã€ã§å­¦ã¶æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤ - åˆå¿ƒè€…ã®ãŸã‚ã®å®Œå…¨ã‚¬ã‚¤ãƒ‰

Notebook

ã¯ã˜ã‚ã«

ã“ã‚“ã«ã¡ã¯ï¼ä»Šå›ã¯Kaggleã®æœ‰åãªã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã€ŒHouse Prices - Advanced Regression Techniquesã€ã«æŒ‘æˆ¦ã—ãŸå­¦ç¿’è¨˜éŒ²ã‚’ã¾ã¨ã‚ã¾ã—ãŸã€‚

ã“ã®ã‚³ãƒ³ãƒšã¯å›å¸°å•é¡Œã®å…¥é–€ã¨ã—ã¦æœ€é©ã§ã€ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã‹ã‚‰ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã¾ã§ã€å®Ÿå‹™ã§ä½¿ãˆã‚‹æŠ€è¡“ã‚’ä¸€é€šã‚Šå­¦ã¹ã¾ã™ã€‚

ã“ã®è¨˜äº‹ã§å­¦ã¹ã‚‹ã“ã¨

âœ… å¤–ã‚Œå€¤ã®æ¤œå‡ºã¨é©åˆ‡ãªå‡¦ç†æ–¹æ³•âœ… æ¬ æå€¤ã‚’ç‰¹å¾´é‡ã®æ€§è³ªã«å¿œã˜ã¦å‡¦ç†ã™ã‚‹æ–¹æ³•âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨ã—ãŸ20ç¨®é¡ä»¥ä¸Šã®ç‰¹å¾´é‡ä½œæˆâœ… éå­¦ç¿’ã‚’é˜²ããŸã‚ã®å…·ä½“çš„ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯âœ… 6ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã£ãŸã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã®å®Ÿè£…

1. ä½¿ç”¨ã™ã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ç’°å¢ƒè¨­å®š

ã¾ãšã¯å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™ã€‚ç‰¹ã«æ—¥æœ¬èªã§ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã«japanize-matplotlibãŒé‡è¦ã§ã™ã€‚

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import japanize_matplotlib  # æ—¥æœ¬èªã‚°ãƒ©ãƒ•å¯¾å¿œ

from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.ensemble import GradientBoostingRegressor
from scipy.stats import skew
from scipy.special import boxcox1p
import xgboost as xgb
import lightgbm as lgb


é‡è¦ãƒã‚¤ãƒ³ãƒˆğŸ’¡

æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šã¯é †åºãŒå¤§åˆ‡ã§ã™ã€‚sns.set(font='IPAexGothic')ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ã€Seabornã®ã‚°ãƒ©ãƒ•ã§ã‚‚æ—¥æœ¬èªãŒæ­£ã—ãè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

2. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åŸºæœ¬çš„ãªç†è§£

train = pd.read_csv('train.csv')
test = pd.read_csv('test.csv')

print(f'è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {train.shape}')  # (1460, 81)
print(f'ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {test.shape}')  # (1459, 80)


è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«ã¯1460ä»¶ã®ä½å®…ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã€81å€‹ã®ç‰¹å¾´é‡ï¼ˆå¤‰æ•°ï¼‰ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ç›®çš„å¤‰æ•°ã¯SalePriceï¼ˆè²©å£²ä¾¡æ ¼ï¼‰ã§ã™ã€‚

3. æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰- ãƒ‡ãƒ¼ã‚¿ã‚’ã€Œè¦‹ã‚‹ã€

3.1 å¤–ã‚Œå€¤ã®ç™ºè¦‹

ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ã™ã‚‹ã“ã¨ã§ã€ç•°å¸¸ãªå€¤ã‚’æŒã¤ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆï¼ˆå¤–ã‚Œå€¤ï¼‰ã‚’ç™ºè¦‹ã§ãã¾ã™ã€‚

# åœ°ä¸Šå±…ä½é¢ç© vs è²©å£²ä¾¡æ ¼ã®æ•£å¸ƒå›³
plt.scatter(train['GrLivArea'], train['SalePrice'])
plt.xlabel('åœ°ä¸Šå±…ä½é¢ç©')
plt.ylabel('è²©å£²ä¾¡æ ¼')
plt.title('å¤–ã‚Œå€¤ã®ç¢ºèª')
plt.show()

ï¼ˆèµ¤ã„ç‚¹ã§å¤–ã‚Œå€¤ã‚’å¼·èª¿ã—ãŸã‚°ãƒ©ãƒ•ï¼‰

ã“ã®ã‚°ãƒ©ãƒ•ã‹ã‚‰ã€é¢ç©ãŒ4000å¹³æ–¹ãƒ•ã‚£ãƒ¼ãƒˆä»¥ä¸Šãªã®ã«ä¾¡æ ¼ãŒ30ä¸‡ãƒ‰ãƒ«æœªæº€ã®ç‰©ä»¶ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ã“ã‚Œã¯æ˜ã‚‰ã‹ã«ç•°å¸¸å€¤ã§ã™ã€‚

3.2 ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒç¢ºèª

# è²©å£²ä¾¡æ ¼ã®åˆ†å¸ƒ
sns.histplot(train['SalePrice'], kde=True)
plt.title('è²©å£²ä¾¡æ ¼ã®åˆ†å¸ƒ')
plt.show()

# å¯¾æ•°å¤‰æ›å¾Œ
sns.histplot(np.log1p(train['SalePrice']), kde=True)
plt.title('è²©å£²ä¾¡æ ¼ã®åˆ†å¸ƒï¼ˆå¯¾æ•°å¤‰æ›å¾Œï¼‰')
plt.show()

å­¦ã‚“ã ã“ã¨ğŸ“š

å…ƒã®ãƒ‡ãƒ¼ã‚¿ã¯å³ã«åã£ãŸåˆ†å¸ƒï¼ˆæ­ªåº¦: 1.88ï¼‰

å¯¾æ•°å¤‰æ›ã«ã‚ˆã‚Šæ­£è¦åˆ†å¸ƒã«è¿‘ã¥ãï¼ˆæ­ªåº¦: 0.12ï¼‰

RMSLEã§è©•ä¾¡ã•ã‚Œã‚‹å•é¡Œã§ã¯å¯¾æ•°å¤‰æ›ãŒå¿…é ˆ

3.3 ç›¸é–¢åˆ†æ

# è²©å£²ä¾¡æ ¼ã¨ç›¸é–¢ã®é«˜ã„ç‰¹å¾´é‡ Top 10
correlations = train.corr()['SalePrice'].sort_values(ascending=False)
print(correlations.head(11))

æœ€ã‚‚ç›¸é–¢ãŒé«˜ã„ã®ã¯ï¼š

OverallQualï¼ˆå…¨ä½“çš„ãªå“è³ªï¼‰: 0.79

GrLivAreaï¼ˆåœ°ä¸Šå±…ä½é¢ç©ï¼‰: 0.71

GarageCarsï¼ˆã‚¬ãƒ¬ãƒ¼ã‚¸åå®¹å°æ•°ï¼‰: 0.64

4. å¤–ã‚Œå€¤ã®é™¤å» - ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’é«˜ã‚ã‚‹ç¬¬ä¸€æ­©

print(f'å¤–ã‚Œå€¤é™¤å»å‰: {train.shape[0]}ä»¶')  # 1460ä»¶

# 1. é¢ç©ã¯å¤§ãã„ã®ã«ä¾¡æ ¼ãŒç•°å¸¸ã«ä½ã„ç‰©ä»¶
train = train.drop(train[(train['GrLivArea'] > 4000) & 
                        (train['SalePrice'] < 300000)].index)

# 2. åœ°ä¸‹å®¤é¢ç©ãŒæ¥µç«¯ã«å¤§ãã„ç‰©ä»¶
train = train.drop(train[train['TotalBsmtSF'] > 3000].index)

# 3. åœŸåœ°é¢ç©ãŒæ¥µç«¯ã«å¤§ãã„ç‰©ä»¶
train = train.drop(train[train['LotArea'] > 100000].index)

print(f'å¤–ã‚Œå€¤é™¤å»å¾Œ: {train.shape[0]}ä»¶')  # ç´„1454ä»¶


ãªãœå¤–ã‚Œå€¤ã‚’é™¤å»ã™ã‚‹ã®ã‹ï¼ŸğŸ¤”

å¤–ã‚Œå€¤ã¯ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ãƒŸã‚¹ã‚„ç‰¹æ®ŠãªçŠ¶æ³ã§ã‚ã‚‹ã“ã¨ãŒå¤šãã€ãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã™ã‚‹å¦¨ã’ã«ãªã‚Šã¾ã™ã€‚æ…é‡ã«åˆ¤æ–­ã—ã¦é™¤å»ã™ã‚‹ã“ã¨ã§ã€äºˆæ¸¬ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ã€‚

5. æ¬ æå€¤å‡¦ç† - ç‰¹å¾´é‡ã®æ€§è³ªã‚’ç†è§£ã™ã‚‹

æ¬ æå€¤å‡¦ç†ã¯ã€Œå˜ç´”ã«å¹³å‡å€¤ã§åŸ‹ã‚ã‚‹ã€ã ã‘ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ç‰¹å¾´é‡ã®æ„å‘³ã‚’è€ƒãˆã¦é©åˆ‡ãªæ–¹æ³•ã‚’é¸ã¶ã“ã¨ãŒé‡è¦ã§ã™ã€‚

5.1 è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®çµåˆ

# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’ä¸€è²«ã—ã¦è¡Œã†ãŸã‚çµåˆ
ntrain = train.shape[0]
y_train = train['SalePrice'].values
all_data = pd.concat([train.drop('SalePrice', axis=1), test], axis=0)


5.2 4ã¤ã®æ¬ æå€¤å‡¦ç†ãƒ‘ã‚¿ãƒ¼ãƒ³

ãƒ‘ã‚¿ãƒ¼ãƒ³1: 'None'ã§åŸ‹ã‚ã‚‹

ã€Œãªã„ã€ã“ã¨ãŒæ„å‘³ã‚’æŒã¤ç‰¹å¾´é‡ï¼ˆãƒ—ãƒ¼ãƒ«ã€ã‚¬ãƒ¬ãƒ¼ã‚¸ã€åœ°ä¸‹å®¤ãªã©ï¼‰

none_cols = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu',
             'GarageType', 'BsmtQual', 'BsmtCond', ...]
for col in none_cols:
    all_data[col] = all_data[col].fillna('None')


ãƒ‘ã‚¿ãƒ¼ãƒ³2: 0ã§åŸ‹ã‚ã‚‹

æ•°å€¤ã§ã€Œãªã„ã€ã‚’è¡¨ç¾ã§ãã‚‹ç‰¹å¾´é‡

zero_cols = ['GarageArea', 'GarageCars', 'TotalBsmtSF', 'MasVnrArea', ...]
for col in zero_cols:
    all_data[col] = all_data[col].fillna(0)


ãƒ‘ã‚¿ãƒ¼ãƒ³3: æœ€é »å€¤ã§åŸ‹ã‚ã‚‹

ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°

mode_cols = ['MSZoning', 'Electrical', 'KitchenQual', ...]
for col in mode_cols:
    all_data[col] = all_data[col].fillna(all_data[col].mode()[0])


ãƒ‘ã‚¿ãƒ¼ãƒ³4: ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ä¸­å¤®å€¤

åœ°åŸŸæ€§ã®ã‚ã‚‹ç‰¹å¾´é‡ï¼ˆé“è·¯ã¾ã§ã®è·é›¢ãªã©ï¼‰

all_data['LotFrontage'] = all_data.groupby('Neighborhood')['LotFrontage'].transform(
    lambda x: x.fillna(x.median()))


å­¦ã‚“ã ã“ã¨ğŸ“š

ãƒ—ãƒ¼ãƒ«ãŒãªã„å®¶ã®PoolQCï¼ˆãƒ—ãƒ¼ãƒ«ã®å“è³ªï¼‰ã¯ã€ŒNoneã€ã¨ã™ã‚‹

ã‚¬ãƒ¬ãƒ¼ã‚¸ãŒãªã„å®¶ã®GarageAreaï¼ˆã‚¬ãƒ¬ãƒ¼ã‚¸é¢ç©ï¼‰ã¯ã€Œ0ã€ã¨ã™ã‚‹

è¿‘éš£ã®å€¤ã‚’å‚è€ƒã«ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šç¾å®Ÿçš„ãªå€¤ã‚’è£œå®Œã§ãã‚‹

6. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° - äºˆæ¸¬ç²¾åº¦ã‚’ä¸Šã’ã‚‹æœ€å¤§ã®æ­¦å™¨

ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨ã¯ã€æ—¢å­˜ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ–°ã—ã„æœ‰ç”¨ãªç‰¹å¾´é‡ã‚’ä½œã‚Šå‡ºã™ä½œæ¥­ã§ã™ã€‚ã“ã‚ŒãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å¤§ããå·¦å³ã—ã¾ã™ã€‚

6.1 é›†ç´„ç‰¹å¾´é‡ï¼ˆåˆè¨ˆãƒ»å¹³å‡ï¼‰

# ç·åºŠé¢ç©ï¼ˆåœ°ä¸‹ + 1éš + 2éšï¼‰
all_data['TotalSF'] = (all_data['TotalBsmtSF'] + 
                       all_data['1stFlrSF'] + 
                       all_data['2ndFlrSF'])

# ç·ãƒã‚¹ãƒ«ãƒ¼ãƒ æ•°ï¼ˆãƒ•ãƒ«ãƒã‚¹ + ãƒãƒ¼ãƒ•ãƒã‚¹Ã—0.5ï¼‰
all_data['TotalBath'] = (all_data['FullBath'] + 
                         0.5 * all_data['HalfBath'] +
                         all_data['BsmtFullBath'] + 
                         0.5 * all_data['BsmtHalfBath'])

# ç·ãƒãƒ¼ãƒé¢ç©
all_data['TotalPorchSF'] = (all_data['OpenPorchSF'] + 
                            all_data['EnclosedPorch'] +
                            all_data['ScreenPorch'] + 
                            all_data['WoodDeckSF'])


6.2 æ™‚ç³»åˆ—ç‰¹å¾´é‡

# å®¶ã®ç¯‰å¹´æ•°
all_data['HouseAge'] = all_data['YrSold'] - all_data['YearBuilt']

# ãƒªãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰ã®å¹´æ•°
all_data['YearsSinceRemod'] = all_data['YrSold'] - all_data['YearRemodAdd']

# ã‚¬ãƒ¬ãƒ¼ã‚¸ã®å¹´é½¢
all_data['GarageAge'] = all_data['YrSold'] - all_data['GarageYrBlt']


6.3 ãƒã‚¤ãƒŠãƒªç‰¹å¾´é‡ï¼ˆã‚ã‚Š/ãªã—ï¼‰

# æ–°ç¯‰ã‹ã©ã†ã‹
all_data['IsNew'] = (all_data['YearBuilt'] == all_data['YrSold']).astype(int)

# ãƒªãƒ•ã‚©ãƒ¼ãƒ ã—ãŸã‹ã©ã†ã‹
all_data['HasRemod'] = (all_data['YearBuilt'] != all_data['YearRemodAdd']).astype(int)

# 2éšãŒã‚ã‚‹ã‹
all_data['Has2ndFloor'] = (all_data['2ndFlrSF'] > 0).astype(int)

# åœ°ä¸‹å®¤ã€ã‚¬ãƒ¬ãƒ¼ã‚¸ã€ãƒ—ãƒ¼ãƒ«ã€æš–ç‚‰ãŒã‚ã‚‹ã‹
all_data['HasBsmt'] = (all_data['TotalBsmtSF'] > 0).astype(int)
all_data['HasGarage'] = (all_data['GarageArea'] > 0).astype(int)
all_data['HasPool'] = (all_data['PoolArea'] > 0).astype(int)
all_data['HasFireplace'] = (all_data['Fireplaces'] > 0).astype(int)


6.4 äº¤äº’ä½œç”¨é …ï¼ˆæœ€é‡è¦ï¼ï¼‰

2ã¤ã®ç‰¹å¾´é‡ã‚’æ›ã‘åˆã‚ã›ã‚‹ã“ã¨ã§ã€ç›¸ä¹—åŠ¹æœã‚’è¡¨ç¾ã—ã¾ã™ã€‚

# å“è³ª Ã— ç·åºŠé¢ç©ï¼ˆé«˜å“è³ªã§åºƒã„å®¶ã¯ç‰¹ã«é«˜ä¾¡ï¼‰
all_data['OverallQual_TotalSF'] = all_data['OverallQual'] * all_data['TotalSF']

# å“è³ª Ã— å±…ä½é¢ç©
all_data['OverallQual_GrLivArea'] = all_data['OverallQual'] * all_data['GrLivArea']

# ç·åˆå“è³ªï¼ˆå“è³ª + çŠ¶æ…‹ï¼‰
all_data['TotalQual'] = all_data['OverallQual'] + all_data['OverallCond']


6.5 æ¯”ç‡ç‰¹å¾´é‡

# åœ°ä¸‹å®¤ã®å‰²åˆï¼ˆåœ°ä¸‹å®¤é¢ç© / ç·åºŠé¢ç©ï¼‰
all_data['Bsmt_Ratio'] = all_data['TotalBsmtSF'] / (all_data['TotalSF'] + 1)

# ã‚¬ãƒ¬ãƒ¼ã‚¸ã®å‰²åˆ
all_data['Garage_Ratio'] = all_data['GarageArea'] / (all_data['TotalSF'] + 1)

# 1éƒ¨å±‹ã‚ãŸã‚Šã®é¢ç©
all_data['AreaPerRoom'] = all_data['GrLivArea'] / (all_data['TotRmsAbvGrd'] + 1)


6.6 ã‚«ãƒ†ã‚´ãƒªã®ã‚°ãƒ«ãƒ¼ãƒ—åŒ–

åœ°åŸŸã‚’ä¾¡æ ¼å¸¯åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã™ã‚‹ã“ã¨ã§ã€ã‚«ãƒ†ã‚´ãƒªæ•°ã‚’æ¸›ã‚‰ã—éå­¦ç¿’ã‚’é˜²ãã¾ã™ã€‚

# å„åœ°åŸŸã®ä¾¡æ ¼ä¸­å¤®å€¤ã‚’è¨ˆç®—
neighborhood_price = train.groupby('Neighborhood')['SalePrice'].median()

# 3ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†é¡ï¼ˆLow, Medium, Highï¼‰
def categorize_neighborhood(neighborhood):
    price = neighborhood_price[neighborhood]
    if price < neighborhood_price.quantile(0.33):
        return 'Low'
    elif price < neighborhood_price.quantile(0.67):
        return 'Medium'
    else:
        return 'High'

all_data['NeighborhoodGroup'] = all_data['Neighborhood'].apply(categorize_neighborhood)


å­¦ã‚“ã ã“ã¨ğŸ“š

ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ãŒé‡è¦ï¼šä¸å‹•ç”£ã®å¸¸è­˜ã‚’æ´»ç”¨

äº¤äº’ä½œç”¨é …ã¯å¼·åŠ›ï¼šãŸã ã—éå­¦ç¿’ã®ãƒªã‚¹ã‚¯ã‚‚ã‚ã‚‹

æ–°ã—ã„è¦–ç‚¹ï¼šåˆè¨ˆã€æ¯”ç‡ã€æ™‚ç³»åˆ—ãªã©å¤šæ§˜ãªè§’åº¦ã§ç‰¹å¾´é‡ã‚’ä½œæˆ

7. ç‰¹å¾´é‡å¤‰æ› - ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒã‚’æ­£è¦åŒ–ã™ã‚‹

7.1 ç›®çš„å¤‰æ•°ã®å¯¾æ•°å¤‰æ›

# RMSLEã§è©•ä¾¡ã•ã‚Œã‚‹ãŸã‚ã€å¯¾æ•°å¤‰æ›ã¯å¿…é ˆ
y_train = np.log1p(y_train)


7.2 Box-Coxå¤‰æ›

æ­ªã‚“ã åˆ†å¸ƒã‚’æŒã¤ç‰¹å¾´é‡ã‚’æ­£è¦åˆ†å¸ƒã«è¿‘ã¥ã‘ã¾ã™ã€‚

# æ­ªåº¦ï¼ˆskewnessï¼‰ã‚’è¨ˆç®—
numeric_feats = all_data.select_dtypes(include=[np.number]).columns
skewed_feats = all_data[numeric_feats].apply(lambda x: skew(x.dropna()))

# æ­ªåº¦ãŒ0.75ä»¥ä¸Šã®ç‰¹å¾´é‡ã«Box-Coxå¤‰æ›ã‚’é©ç”¨
skewed_features = skewed_feats[abs(skewed_feats) > 0.75].index

lam = 0.15
for feat in skewed_features:
    all_data[feat] = boxcox1p(all_data[feat], lam)


7.3 One-Hot Encoding

ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’æ•°å€¤ã«å¤‰æ›ã—ã¾ã™ã€‚

all_data = pd.get_dummies(all_data)
print(f'ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¾Œ: {all_data.shape[1]}åˆ—')  # ç´„330åˆ—


å­¦ã‚“ã ã“ã¨ğŸ“š

å¯¾æ•°å¤‰æ›ã«ã‚ˆã‚Šæ­ªåº¦ãŒ0ã«è¿‘ã¥ãï¼ˆæ­£è¦åˆ†å¸ƒã«è¿‘ããªã‚‹ï¼‰

æ­£è¦åˆ†å¸ƒã«è¿‘ã„ãƒ‡ãƒ¼ã‚¿ã¯ã€ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã—ã‚„ã™ã„

One-Hot Encodingã§ã€ŒNeighborhoodãŒStoneBrã€â†’ã€ŒNeighborhood_StoneBr=1ã€ã«å¤‰æ›

8. ç‰¹å¾´é‡é¸æŠ - éå­¦ç¿’ã‚’é˜²ãé‡è¦ãªã‚¹ãƒ†ãƒƒãƒ—

ç‰¹å¾´é‡ãŒå¤šã™ãã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«éé©åˆï¼ˆéå­¦ç¿’ï¼‰ã—ã¦ã—ã¾ã„ã¾ã™ã€‚

8.1 LightGBMã§é‡è¦åº¦ã‚’è¨ˆç®—

# ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
X_train = all_data[:ntrain]
X_test = all_data[ntrain:]

# ç‰¹å¾´é‡é‡è¦åº¦ã®è¨ˆç®—
lgb_selector = lgb.LGBMRegressor(n_estimators=500, learning_rate=0.05, random_state=42)
lgb_selector.fit(X_train, y_train)

feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': lgb_selector.feature_importances_
}).sort_values('importance', ascending=False)


8.2 é‡è¦åº¦ã®ä½ã„ç‰¹å¾´é‡ã‚’é™¤å»

# é‡è¦åº¦ãŒ5ä»¥ä¸Šã®ç‰¹å¾´é‡ã®ã¿ã‚’ä½¿ç”¨
threshold = 5
important_features = feature_importance[
    feature_importance['importance'] > threshold
]['feature'].tolist()

print(f'å…ƒã®ç‰¹å¾´é‡æ•°: {X_train.shape[1]}')      # ç´„330åˆ—
print(f'é¸æŠå¾Œ: {len(important_features)}')      # ç´„150åˆ—
print(f'é™¤å»: {X_train.shape[1] - len(important_features)}')  # ç´„180åˆ—

X_train = X_train[important_features]
X_test = X_test[important_features]


å­¦ã‚“ã ã“ã¨ğŸ“š

ç´„åŠåˆ†ã®ç‰¹å¾´é‡ã‚’é™¤å»ã—ã¦ã‚‚ç²¾åº¦ã¯ä¸‹ãŒã‚‰ãªã„

é‡è¦åº¦ã®ä½ã„ç‰¹å¾´é‡ã¯ã€Œãƒã‚¤ã‚ºã€ã¨ãªã‚Šç²¾åº¦ã‚’ä¸‹ã’ã‚‹

CVã‚¹ã‚³ã‚¢ã¨LBã‚¹ã‚³ã‚¢ã®ã‚®ãƒ£ãƒƒãƒ—ãŒç¸®å°ï¼ˆéå­¦ç¿’ãŒæ¸›å°‘ï¼‰

9. ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ - 6ã¤ã®ç•°ãªã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

9.1 ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–¢æ•°

def rmsle_cv(model, X, y, n_folds=5):
    """5-fold CVã§RMSLEã‚’è¨ˆç®—"""
    kf = KFold(n_folds, shuffle=True, random_state=42)
    rmse = np.sqrt(-cross_val_score(
        model, X, y, 
        scoring='neg_mean_squared_error', 
        cv=kf
    ))
    return rmse


9.2 ç·šå½¢ãƒ¢ãƒ‡ãƒ«ï¼ˆæ­£å‰‡åŒ–ä»˜ãï¼‰

# Ridgeå›å¸°ï¼ˆL2æ­£å‰‡åŒ–ï¼‰
ridge = Ridge(alpha=15.0, random_state=42)
ridge_scores = rmsle_cv(ridge, X_train, y_train)

# Lassoå›å¸°ï¼ˆL1æ­£å‰‡åŒ– + ç‰¹å¾´é‡é¸æŠï¼‰
lasso = Lasso(alpha=0.0005, random_state=42, max_iter=10000)
lasso_scores = rmsle_cv(lasso, X_train, y_train)

# ElasticNetï¼ˆL1 + L2æ­£å‰‡åŒ–ï¼‰
elastic = ElasticNet(alpha=0.0005, l1_ratio=0.9, random_state=42, max_iter=10000)
elastic_scores = rmsle_cv(elastic, X_train, y_train)


9.3 å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ï¼ˆéå­¦ç¿’å¯¾ç­–å¼·åŒ–ç‰ˆï¼‰

# XGBoost
xgboost = xgb.XGBRegressor(
    n_estimators=3000,
    learning_rate=0.01,
    max_depth=3,           # æœ¨ã®æ·±ã•ã‚’åˆ¶é™
    min_child_weight=3,    # ãƒãƒ¼ãƒ‰åˆ†å‰²ã‚’å³ã—ã
    gamma=0.1,             # ã‚²ã‚¤ãƒ³é–¾å€¤
    subsample=0.6,         # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ç‡
    colsample_bytree=0.6,  # ç‰¹å¾´é‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    reg_alpha=0.0001,      # L1æ­£å‰‡åŒ–
    reg_lambda=2,          # L2æ­£å‰‡åŒ–
    random_state=42
)
xgb_scores = rmsle_cv(xgboost, X_train, y_train)

# LightGBM
lightgbm = lgb.LGBMRegressor(
    n_estimators=3000,
    learning_rate=0.01,
    max_depth=3,
    num_leaves=8,          # è‘‰ã®æ•°ã‚’åˆ¶é™
    min_child_samples=30,  # æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
    subsample=0.6,
    colsample_bytree=0.6,
    reg_alpha=0.2,         # L1æ­£å‰‡åŒ–
    reg_lambda=0.2,        # L2æ­£å‰‡åŒ–
    random_state=42
)
lgb_scores = rmsle_cv(lightgbm, X_train, y_train)

# Gradient Boosting
gb = GradientBoostingRegressor(
    n_estimators=3000,
    learning_rate=0.01,
    max_depth=3,
    min_samples_split=10,
    min_samples_leaf=8,
    subsample=0.7,
    random_state=42
)
gb_scores = rmsle_cv(gb, X_train, y_train)


9.4 ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®æ¯”è¼ƒ

model_scores = pd.DataFrame({
    'ãƒ¢ãƒ‡ãƒ«': ['Ridge', 'Lasso', 'ElasticNet', 'XGBoost', 'LightGBM', 'GradientBoosting'],
    'å¹³å‡RMSLE': [...],
    'æ¨™æº–åå·®': [...]
}).sort_values('å¹³å‡RMSLE')


éå­¦ç¿’ã‚’é˜²ããƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã®ãƒã‚¤ãƒ³ãƒˆğŸ’¡

XGBoost/LightGBM

max_depth=3: æœ¨ã®æ·±ã•ã‚’æµ…ãã™ã‚‹ â†’ è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã™ããªã„

subsample=0.6: ãƒ‡ãƒ¼ã‚¿ã®60%ã ã‘ä½¿ã£ã¦å­¦ç¿’ â†’ ãƒ©ãƒ³ãƒ€ãƒ æ€§ã‚’æŒãŸã›ã‚‹

reg_lambda=2: L2æ­£å‰‡åŒ–ã‚’å¼·åŒ– â†’ é‡ã¿ãŒå¤§ãããªã‚Šã™ãã‚‹ã®ã‚’é˜²ã

Ridge/Lasso/ElasticNet

alpha: å¤§ãã„ã»ã©æ­£å‰‡åŒ–ãŒå¼·ã„ â†’ éå­¦ç¿’ã‚’é˜²ã

å­¦ã‚“ã ã“ã¨ğŸ“š

å¤šæ§˜ãªãƒ¢ãƒ‡ãƒ«ã‚’è©¦ã™ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿ã«æœ€é©ãªãƒ¢ãƒ‡ãƒ«ã‚’è¦‹ã¤ã‘ã‚‹

æ­£å‰‡åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®èª¿æ•´ãŒéå­¦ç¿’å¯¾ç­–ã®éµ

ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§çœŸã®æ€§èƒ½ã‚’æ¸¬å®š

10. ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« - è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®åŠ›ã‚’åˆã‚ã›ã‚‹

ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã¨ã¯ã€è¤‡æ•°ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’çµ„ã¿åˆã‚ã›ã¦ã€ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ãŒæœ€çµ‚äºˆæ¸¬ã‚’è¡Œã†æ‰‹æ³•ã§ã™ã€‚

10.1 ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã®ä»•çµ„ã¿

[è¨“ç·´ãƒ‡ãƒ¼ã‚¿]
    â†“
[ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«1, 2, 3, 4, 5, 6]ï¼ˆ5-fold CVã§äºˆæ¸¬ï¼‰
    â†“
[Out-of-foldäºˆæ¸¬] â†’ ã“ã‚Œã‚’ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®å…¥åŠ›ã¨ã™ã‚‹
    â†“
[ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆRidgeï¼‰] â†’ æœ€çµ‚äºˆæ¸¬


10.2 å®Ÿè£…

class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):
    """ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å®Ÿè£…"""
    
    def __init__(self, base_models, meta_model, n_folds=5):
        self.base_models = base_models
        self.meta_model = meta_model
        self.n_folds = n_folds
   
    def fit(self, X, y):
        # Out-of-foldäºˆæ¸¬ã®ç”Ÿæˆ
        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))
        
        for i, model in enumerate(self.base_models):
            for train_index, holdout_index in kfold.split(X, y):
                instance = clone(model)
                instance.fit(X[train_index], y[train_index])
                y_pred = instance.predict(X[holdout_index])
                out_of_fold_predictions[holdout_index, i] = y_pred
        
        # ãƒ¡ã‚¿ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
        self.meta_model_.fit(out_of_fold_predictions, y)
        return self
   
    def predict(self, X):
        meta_features = ...  # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’é›†ç´„
        return self.meta_model_.predict(meta_features)

# ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
stacked_model = StackingAveragedModels(
    base_models=[ridge, lasso, elastic, xgboost, lightgbm, gb],
    meta_model=Ridge(alpha=10.0)
)

stacking_scores = rmsle_cv(stacked_model, X_train, y_train)


10.3 ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã®åŠ¹æœ

æœ€è‰¯ã®å˜ä¸€ãƒ¢ãƒ‡ãƒ«: 0.1080
ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°: 0.1065
æ”¹å–„ç‡: 1.39%


å­¦ã‚“ã ã“ã¨ğŸ“š

ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã¯å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šå®‰å®šã—ãŸäºˆæ¸¬ãŒå¯èƒ½

å„ãƒ¢ãƒ‡ãƒ«ã®å¼·ã¿ã‚’æ´»ã‹ã—ã€å¼±ç‚¹ã‚’è£œå®Œã§ãã‚‹

Out-of-foldäºˆæ¸¬ã«ã‚ˆã‚Šéå­¦ç¿’ã‚’é˜²ã

11. ç‰¹å¾´é‡é‡è¦åº¦ã®ç¢ºèª

# LightGBMã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’å¯è¦–åŒ–
feature_imp = pd.DataFrame({
    'feature': X_train.columns,
    'importance': lightgbm.feature_importances_
}).sort_values('importance', ascending=False)

# ä¸Šä½20ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
plt.barh(range(20), feature_imp.head(20)['importance'])
plt.yticks(range(20), feature_imp.head(20)['feature'])
plt.title('LightGBM - ç‰¹å¾´é‡é‡è¦åº¦ Top 20')
plt.show()

é‡è¦ãªç‰¹å¾´é‡ Top 5

OverallQual - å…¨ä½“çš„ãªå“è³ª

GrLivArea - åœ°ä¸Šå±…ä½é¢ç©

TotalSF - ç·åºŠé¢ç©ï¼ˆä½œæˆã—ãŸç‰¹å¾´é‡ï¼ï¼‰

GarageCars - ã‚¬ãƒ¬ãƒ¼ã‚¸åå®¹å°æ•°

OverallQual_TotalSF - å“è³ªÃ—ç·åºŠé¢ç©ï¼ˆä½œæˆã—ãŸäº¤äº’ä½œç”¨é …ï¼ï¼‰

è‡ªåˆ†ã§ä½œæˆã—ãŸç‰¹å¾´é‡ãŒä¸Šä½ã«ãƒ©ãƒ³ã‚¯ã‚¤ãƒ³ã—ã¦ã„ã¾ã™ï¼ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®åŠ¹æœãŒç¢ºèªã§ãã¾ã—ãŸã€‚

12. äºˆæ¸¬ã¨æå‡º

12.1 é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«

CVã‚¹ã‚³ã‚¢ãŒè‰¯ã„ãƒ¢ãƒ‡ãƒ«ã«é«˜ã„é‡ã¿ã‚’è¨­å®šã—ã¾ã™ã€‚

# å„ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
pred_ridge = ridge.predict(X_test)
pred_lasso = lasso.predict(X_test)
pred_elastic = elastic.predict(X_test)
pred_xgb = xgboost.predict(X_test)
pred_lgb = lightgbm.predict(X_test)
pred_gb = gb.predict(X_test)
pred_stacked = stacked_model.predict(X_test)

# é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
ensemble_pred = (
    0.50 * pred_stacked +      # ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ï¼ˆæœ€ã‚‚é‡è¦–ï¼‰
    0.20 * pred_lasso +        # CVã‚¹ã‚³ã‚¢è‰¯å¥½
    0.15 * pred_elastic +      # CVã‚¹ã‚³ã‚¢è‰¯å¥½
    0.10 * pred_gb +           # CVã‚¹ã‚³ã‚¢è‰¯å¥½
    0.05 * pred_ridge          # å®‰å®šæ€§ã®ãŸã‚
)

# å¯¾æ•°å¤‰æ›ã‚’å…ƒã«æˆ»ã™
final_predictions = np.expm1(ensemble_pred)


12.2 æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ

submission = pd.DataFrame({
    'Id': test['Id'],
    'SalePrice': final_predictions
})
submission.to_csv('submission.csv', index=False)


ã¾ã¨ã‚ - å­¦ã‚“ã é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ

1. ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ã®é‡è¦æ€§

âœ… å¤–ã‚Œå€¤ã¯æ…é‡ã«åˆ¤æ–­ã—ã¦é™¤å»âœ… æ¬ æå€¤ã¯ç‰¹å¾´é‡ã®æ€§è³ªã«å¿œã˜ã¦å‡¦ç†

2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒæ€§èƒ½ã®éµ

âœ… ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ï¼ˆä¸å‹•ç”£ã®å¸¸è­˜ï¼‰ã‚’æ´»ç”¨âœ… é›†ç´„ã€æ™‚ç³»åˆ—ã€äº¤äº’ä½œç”¨ã€æ¯”ç‡ãªã©å¤šæ§˜ãªè¦–ç‚¹ã§ä½œæˆâœ… 20å€‹ä»¥ä¸Šã®æ–°ç‰¹å¾´é‡ã‚’ä½œæˆã—ã€å¤šããŒé‡è¦åº¦ä¸Šä½ã«

3. éå­¦ç¿’ã¨ã®æˆ¦ã„

âœ… ç‰¹å¾´é‡é¸æŠ: ç´„åŠåˆ†ã®ç‰¹å¾´é‡ã‚’é™¤å»ã—ã¦ãƒã‚¤ã‚ºå‰Šæ¸›âœ… æ­£å‰‡åŒ–: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã§è¤‡é›‘ã•ã‚’åˆ¶å¾¡âœ… ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³: çœŸã®æ€§èƒ½ã‚’æ¸¬å®šâœ… CVã¨LBã®ã‚®ãƒ£ãƒƒãƒ—: éå­¦ç¿’ã®æŒ‡æ¨™

4. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã®åŠ›

âœ… å¤šæ§˜ãªãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã¦å®‰å®šã—ãŸäºˆæ¸¬âœ… ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã¯å˜ç´”ãªå¹³å‡ã‚ˆã‚ŠåŠ¹æœçš„âœ… é‡ã¿ä»˜ã‘ã¯CVã‚¹ã‚³ã‚¢ã«åŸºã¥ã„ã¦èª¿æ•´

5. å®Ÿå‹™ã§ä½¿ãˆã‚‹ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

âœ… å†ç¾æ€§ã®ç¢ºä¿: random_stateã‚’å›ºå®šâœ… æ®µéšçš„ãªæ”¹å–„: ä¸€åº¦ã«å¤šãã‚’å¤‰ãˆãªã„âœ… å¯è¦–åŒ–: ã‚°ãƒ©ãƒ•ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç†è§£âœ… ã‚³ãƒ¡ãƒ³ãƒˆ: ç†ç”±ã‚’è¨˜éŒ²ã—ã¦å¾Œã‹ã‚‰è¦‹è¿”ã›ã‚‹ã‚ˆã†ã«

ã•ã‚‰ãªã‚‹æ”¹å–„ã®ã‚¢ã‚¤ãƒ‡ã‚¢

ä¸­ç´šè€…å‘ã‘

ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒï¼ˆGridSearchCVï¼‰

ç‰¹å¾´é‡é¸æŠã®é–¾å€¤ã‚’æœ€é©åŒ–

ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿ã®è‡ªå‹•æœ€é©åŒ–

ä¸Šç´šè€…å‘ã‘

SHAPå€¤ã«ã‚ˆã‚‹ç‰¹å¾´é‡ã®è©³ç´°åˆ†æ

2æ®µéšã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°

ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã®è¿½åŠ 

Optunaã«ã‚ˆã‚‹é«˜åº¦ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–

ãŠã‚ã‚Šã«

ã“ã®ã‚³ãƒ³ãƒšã‚’é€šã˜ã¦ã€æ©Ÿæ¢°å­¦ç¿’ã®å®Ÿè·µçš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä¸€é€šã‚Šå­¦ã¶ã“ã¨ãŒã§ãã¾ã—ãŸã€‚

æœ€ã‚‚é‡è¦ãªã®ã¯ã€Œãƒ‡ãƒ¼ã‚¿ã‚’ç†è§£ã™ã‚‹ã“ã¨ã€ã€€ã§ã™ã€‚å¯è¦–åŒ–ã‚„ç›¸é–¢åˆ†æã‚’é€šã˜ã¦ãƒ‡ãƒ¼ã‚¿ã®ç‰¹æ€§ã‚’æŠŠæ¡ã—ã€ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã‚’æ´»ç”¨ã™ã‚‹ã“ã¨ã§ã€åŠ¹æœçš„ãªç‰¹å¾´é‡ã‚’ä½œæˆã§ãã¾ã™ã€‚

ã¾ãŸã€éå­¦ç¿’å¯¾ç­–ã¯å®Ÿå‹™ã§ã‚‚éå¸¸ã«é‡è¦ã§ã™ã€‚ç‰¹å¾´é‡é¸æŠã€æ­£å‰‡åŒ–ã€ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãªã©ã€æ§˜ã€…ãªãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã‚’çµ„ã¿åˆã‚ã›ã¦ä½¿ã„ã“ãªã›ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ã‚‡ã†ã€‚

çš†ã•ã‚“ã‚‚ãœã²Kaggleã«æŒ‘æˆ¦ã—ã¦ã¿ã¦ãã ã•ã„ï¼

å‚è€ƒãƒªã‚½ãƒ¼ã‚¹

Kaggle: House Prices Competition

scikit-learn å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

XGBoost å…¬å¼ã‚¬ã‚¤ãƒ‰

LightGBM å…¬å¼ã‚¬ã‚¤ãƒ‰

