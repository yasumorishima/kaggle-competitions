#!/usr/bin/env python
# coding: utf-8

# # ğŸš€ Spaceship Titanic - å®Œå…¨å­¦ç¿’ã‚¬ã‚¤ãƒ‰ï¼ˆã‚°ãƒ©ãƒ•ä»˜ãï¼‰
# ## ğŸ“Œ ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«ã¤ã„ã¦
# Kaggleã€ŒSpaceship Titanicã€ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã§**0.805ã‚’é”æˆ**ã—ãŸæ‰‹æ³•ã‚’ã€
# **è±Šå¯Œãªã‚°ãƒ©ãƒ•ã¨å¯è¦–åŒ–**ã§å­¦ç¿’ç”¨ã«ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚
# ---
# ## ğŸ¯ é”æˆã—ãŸçµæœ
# | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | Kaggleã‚¹ã‚³ã‚¢ | ç‰¹å¾´é‡æ•° |
# |-----------|-------------|------|----------|
# | åŸºæœ¬ç‰ˆ | 0.80336 |  | 38 |
# | **æœ€é©åŒ–ç‰ˆ** | **0.80523** | **** | 50 |
# ---
# ## ğŸ“Š ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ç‰¹å¾´
# ### âœ… å«ã¾ã‚Œã‚‹ã‚°ãƒ©ãƒ•
# 1. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®åˆ†å¸ƒï¼ˆæ£’ã‚°ãƒ©ãƒ•ãƒ»å††ã‚°ãƒ©ãƒ•ï¼‰
# 2. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã¨Transportedã®é–¢ä¿‚
# 3. æ•°å€¤å¤‰æ•°ã®åˆ†å¸ƒï¼ˆãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ é‡ã­åˆã‚ã›ï¼‰
# 4. ç·æ”¯å‡ºé¡ã¨Transportedã®é–¢ä¿‚
# 5. Cabinï¼ˆãƒ‡ãƒƒã‚­ãƒ»ã‚µã‚¤ãƒ‰ï¼‰ã®åˆ†æ
# 6. æ•°å€¤å¤‰æ•°ã®ç›¸é–¢è¡Œåˆ—ï¼ˆãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼‰
# 7. ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã®åˆ†å¸ƒã¨è»¢é€ç‡
# 8. å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®è»¢é€ç‡
# 9. ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆãƒˆãƒƒãƒ—20ï¼‰
# 10. ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®æ¯”è¼ƒ
# ### ğŸ“š å­¦ã¹ã‚‹ã“ã¨
# - ãƒ‡ãƒ¼ã‚¿ã®ç†è§£ï¼ˆEDAï¼‰
# - ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
# - ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã®æ´»ç”¨æ³•
# - æ¬ æå€¤ã®è³¢ã„å‡¦ç†
# - è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨æ¯”è¼ƒ
# - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•
# ---

# ## 1ï¸âƒ£ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã—ã¾ã™ã€‚

# In[1]:


# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆæœ€åˆã«å®Ÿè¡Œï¼‰
get_ipython().system('pip install japanize-matplotlib -q')

# ãƒ‡ãƒ¼ã‚¿å‡¦ç†
import pandas as pd
import numpy as np

# å¯è¦–åŒ–
import matplotlib.pyplot as plt
import seaborn as sns
import japanize_matplotlib  # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œ

# æ©Ÿæ¢°å­¦ç¿’
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# XGBoostã¨LightGBMã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã¨èª­ã¿è¾¼ã¿
try:
    import xgboost as xgb
except:
    import subprocess
    subprocess.check_call(['pip', 'install', 'xgboost', '--break-system-packages'])
    import xgboost as xgb

try:
    import lightgbm as lgb
except:
    import subprocess
    subprocess.check_call(['pip', 'install', 'lightgbm', '--break-system-packages'])
    import lightgbm as lgb

# è­¦å‘Šã®éè¡¨ç¤º
import warnings
warnings.filterwarnings('ignore')

# ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# ã€é‡è¦ã€‘Seabornã®ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆæ—¥æœ¬èªæ–‡å­—åŒ–ã‘å¯¾ç­–ï¼‰
sns.set(font='IPAexGothic')

# ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰å›ºå®šï¼ˆå†ç¾æ€§ã®ãŸã‚ï¼‰
RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

print("âœ… ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†ï¼")
print("âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šå®Œäº†ï¼")


# ## 2ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿

# In[2]:


# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
train_df = pd.read_csv('/kaggle/input/spaceship-titanic/train.csv')
test_df = pd.read_csv('/kaggle/input/spaceship-titanic/test.csv')
sample_submission = pd.read_csv('/kaggle/input/spaceship-titanic/sample_submission.csv')

print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚º: {train_df.shape}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚º: {test_df.shape}")

# å…ƒãƒ‡ãƒ¼ã‚¿ã®ã‚³ãƒ”ãƒ¼ã‚’ä¿å­˜
train_original = train_df.copy()
test_original = test_df.copy()


# ## 3ï¸âƒ£ ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±ç¢ºèª
# ### 3.1 æœ€åˆã®æ•°è¡Œã‚’ç¢ºèª

# In[3]:


train_df.head(10)


# ### 3.2 ãƒ‡ãƒ¼ã‚¿ã®å‹ã¨æ¬ æå€¤ã®ç¢ºèª

# In[4]:


train_df.info()


# In[5]:


# æ¬ æå€¤ã®å‰²åˆã‚’ç¢ºèª
missing_train = pd.DataFrame({
    'æ¬ ææ•°': train_df.isnull().sum(),
    'æ¬ æç‡(%)': (train_df.isnull().sum() / len(train_df)) * 100
})
missing_train = missing_train[missing_train['æ¬ ææ•°'] > 0].sort_values('æ¬ æç‡(%)', ascending=False)
print("\nã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ¬ æå€¤ã€‘")
print(missing_train)


# ### 3.3 çµ±è¨ˆæƒ…å ±ã®ç¢ºèª

# In[6]:


train_df.describe()


# ### 3.4 ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®åˆ†å¸ƒ

# In[7]:


# Transportedã®åˆ†å¸ƒ
transported_counts = train_df['Transported'].value_counts()
print("ã€Transportedï¼ˆç•°æ¬¡å…ƒè»¢é€ï¼‰ã®åˆ†å¸ƒã€‘")
print(transported_counts)
print(f"\nè»¢é€ã•ã‚ŒãŸå‰²åˆ: {transported_counts[True] / len(train_df) * 100:.2f}%")

# å¯è¦–åŒ–
fig, ax = plt.subplots(1, 2, figsize=(14, 5))
transported_counts.plot(kind='bar', ax=ax[0], color=['skyblue', 'salmon'])
ax[0].set_title('Transportedã®åˆ†å¸ƒ', fontsize=14, weight='bold')
ax[0].set_xlabel('Transported')
ax[0].set_ylabel('äººæ•°')
ax[0].set_xticklabels(['False', 'True'], rotation=0)
for container in ax[0].containers:
    ax[0].bar_label(container)

ax[1].pie(transported_counts, labels=['Not Transported', 'Transported'], 
          autopct='%1.1f%%', colors=['skyblue', 'salmon'], startangle=90)
ax[1].set_title('Transportedã®å‰²åˆ', fontsize=14, weight='bold')
plt.tight_layout()
plt.show()


# ## 4ï¸âƒ£ åŸºæœ¬çš„ãªç‰¹å¾´é‡æŠ½å‡º
# ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è¿½åŠ ã®æƒ…å ±ã‚’æŠ½å‡ºã—ã¾ã™ã€‚

# In[8]:


def extract_basic_features(df):
    """
    PassengerIdã€Cabinã€Nameã‹ã‚‰åŸºæœ¬çš„ãªç‰¹å¾´é‡ã‚’æŠ½å‡º
    """
    # PassengerIdã¯ "gggg_pp" ã®å½¢å¼
    # gggg: ã‚°ãƒ«ãƒ¼ãƒ—IDã€pp: ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®ç•ªå·
    df['GroupId'] = df['PassengerId'].apply(lambda x: x.split('_')[0])
    df['GroupNum'] = df['PassengerId'].apply(lambda x: int(x.split('_')[1]))

    # Cabinã¯ "deck/num/side" ã®å½¢å¼
    # ä¾‹: "B/0/P" -> Deck:B, Num:0, Side:P
    df['Cabin_Deck'] = df['Cabin'].apply(lambda x: x.split('/')[0] if pd.notna(x) else np.nan)
    df['Cabin_Num'] = df['Cabin'].apply(lambda x: int(x.split('/')[1]) if pd.notna(x) else np.nan)
    df['Cabin_Side'] = df['Cabin'].apply(lambda x: x.split('/')[2] if pd.notna(x) else np.nan)

    # Nameã‹ã‚‰å§“ã¨åã‚’åˆ†é›¢
    df['FirstName'] = df['Name'].apply(lambda x: x.split()[0] if pd.notna(x) else np.nan)
    df['LastName'] = df['Name'].apply(lambda x: x.split()[1] if pd.notna(x) and len(x.split()) > 1 else np.nan)

    # æ”¯å‡ºé …ç›®ã®åˆè¨ˆ
    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']
    df['TotalSpending'] = df[spending_cols].sum(axis=1)

    return df

train_df = extract_basic_features(train_df)
test_df = extract_basic_features(test_df)

print("âœ… åŸºæœ¬çš„ãªç‰¹å¾´é‡æŠ½å‡ºå®Œäº†")
print(f"\næ–°ã—ã„ç‰¹å¾´é‡: GroupId, GroupNum, Cabin_Deck, Cabin_Num, Cabin_Side, FirstName, LastName, TotalSpending")


# ## 5ï¸âƒ£ æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰
# ### 5.1 ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é–¢ä¿‚

# In[9]:


# ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ãƒªã‚¹ãƒˆ
categorical_cols = ['HomePlanet', 'CryoSleep', 'Destination', 'VIP']

fig, axes = plt.subplots(2, 2, figsize=(16, 12))
axes = axes.flatten()

for idx, col in enumerate(categorical_cols):
    # å„ã‚«ãƒ†ã‚´ãƒªã”ã¨ã®Transportedç‡
    transported_rate = train_df.groupby(col)['Transported'].mean().sort_values(ascending=False)
    transported_rate.plot(kind='bar', ax=axes[idx], color='steelblue')
    axes[idx].set_title(f'{col}ã”ã¨ã®Transportedç‡', fontsize=12, weight='bold')
    axes[idx].set_ylabel('Transportedç‡')
    axes[idx].set_ylim([0, 1])
    axes[idx].axhline(y=0.5, color='red', linestyle='--', label='50%')
    axes[idx].legend()

    # å„ãƒãƒ¼ã®ä¸Šã«æ•°å€¤ã‚’è¡¨ç¤º
    for container in axes[idx].containers:
        axes[idx].bar_label(container, fmt='%.2f')

plt.tight_layout()
plt.show()


# **è¦³å¯Ÿãƒã‚¤ãƒ³ãƒˆ**:
# - CryoSleepãŒTrueã®äººã¯è»¢é€ç‡ãŒéå¸¸ã«é«˜ã„
# - HomePlanetã‚„Destinationã«ã‚ˆã£ã¦ã‚‚è»¢é€ç‡ãŒç•°ãªã‚‹
# - VIPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚‚å½±éŸ¿ãŒã‚ã‚‹å¯èƒ½æ€§

# ### 5.2 æ•°å€¤å¤‰æ•°ã®åˆ†å¸ƒ

# In[10]:


# æ•°å€¤å¤‰æ•°ã®ãƒªã‚¹ãƒˆ
numerical_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']

fig, axes = plt.subplots(3, 2, figsize=(16, 15))
axes = axes.flatten()

for idx, col in enumerate(numerical_cols):
    # Transportedã”ã¨ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    train_df[train_df['Transported'] == False][col].hist(ax=axes[idx], alpha=0.6, 
                                                           bins=30, label='Not Transported', color='skyblue')
    train_df[train_df['Transported'] == True][col].hist(ax=axes[idx], alpha=0.6, 
                                                          bins=30, label='Transported', color='salmon')
    axes[idx].set_title(f'{col}ã®åˆ†å¸ƒ', fontsize=12, weight='bold')
    axes[idx].set_xlabel(col)
    axes[idx].set_ylabel('é »åº¦')
    axes[idx].legend()

plt.tight_layout()
plt.show()


# **è¦³å¯Ÿãƒã‚¤ãƒ³ãƒˆ**:
# - å¤šãã®äººãŒå„æ–½è¨­ã§0å††ã—ã‹ä½¿ã£ã¦ã„ãªã„ï¼ˆCryoSleepä¸­ã®å¯èƒ½æ€§ï¼‰
# - è»¢é€ã•ã‚ŒãŸäººã¯æ”¯å‡ºãŒå°‘ãªã„å‚¾å‘

# ### 5.3 ç·æ”¯å‡ºé¡ã¨Transportedã®é–¢ä¿‚

# In[11]:


# TotalSpendingã¨Transportedã®é–¢ä¿‚
fig, ax = plt.subplots(1, 2, figsize=(16, 5))

train_df[train_df['Transported'] == False]['TotalSpending'].hist(ax=ax[0], alpha=0.6, 
                                                                   bins=50, label='Not Transported', color='skyblue')
train_df[train_df['Transported'] == True]['TotalSpending'].hist(ax=ax[0], alpha=0.6, 
                                                                  bins=50, label='Transported', color='salmon')
ax[0].set_title('ç·æ”¯å‡ºé¡ã®åˆ†å¸ƒ', fontsize=14, weight='bold')
ax[0].set_xlabel('ç·æ”¯å‡ºé¡')
ax[0].set_ylabel('é »åº¦')
ax[0].legend()

# ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
train_df.boxplot(column='TotalSpending', by='Transported', ax=ax[1])
ax[1].set_title('Transportedã”ã¨ã®ç·æ”¯å‡ºé¡', fontsize=14, weight='bold')
ax[1].set_xlabel('Transported')
ax[1].set_ylabel('ç·æ”¯å‡ºé¡')
plt.suptitle('')
plt.tight_layout()
plt.show()

print(f"\nã€ç·æ”¯å‡ºé¡ã®çµ±è¨ˆã€‘")
print(f"Not Transportedã®å¹³å‡: {train_df[train_df['Transported'] == False]['TotalSpending'].mean():.2f}")
print(f"Transportedã®å¹³å‡: {train_df[train_df['Transported'] == True]['TotalSpending'].mean():.2f}")


# ### 5.4 Cabinãƒ‡ãƒ¼ã‚¿ã®åˆ†æ

# In[12]:


# Cabin_Deckã¨Transportedã®é–¢ä¿‚
fig, axes = plt.subplots(1, 2, figsize=(16, 5))

deck_transported = train_df.groupby('Cabin_Deck')['Transported'].mean().sort_values(ascending=False)
deck_transported.plot(kind='bar', ax=axes[0], color='steelblue')
axes[0].set_title('ãƒ‡ãƒƒã‚­ã”ã¨ã®Transportedç‡', fontsize=14, weight='bold')
axes[0].set_ylabel('Transportedç‡')
axes[0].axhline(y=0.5, color='red', linestyle='--', label='50%')
axes[0].legend()

# Cabin_Sideã¨Transportedã®é–¢ä¿‚
side_transported = train_df.groupby('Cabin_Side')['Transported'].mean().sort_values(ascending=False)
side_transported.plot(kind='bar', ax=axes[1], color='coral')
axes[1].set_title('ã‚µã‚¤ãƒ‰ï¼ˆP/Sï¼‰ã”ã¨ã®Transportedç‡', fontsize=14, weight='bold')
axes[1].set_ylabel('Transportedç‡')
axes[1].axhline(y=0.5, color='red', linestyle='--', label='50%')
axes[1].legend()

plt.tight_layout()
plt.show()


# **è¦³å¯Ÿãƒã‚¤ãƒ³ãƒˆ**:
# - ãƒ‡ãƒƒã‚­ã«ã‚ˆã£ã¦è»¢é€ç‡ãŒå¤§ããç•°ãªã‚‹
# - èˆ¹å®¤ã®ã‚µã‚¤ãƒ‰ï¼ˆPortã‹Starboardï¼‰ã‚‚å½±éŸ¿ãŒã‚ã‚‹

# ### 5.5 ç›¸é–¢åˆ†æ

# In[13]:


# æ•°å€¤å¤‰æ•°ã®ç›¸é–¢è¡Œåˆ—
correlation_cols = numerical_cols + ['TotalSpending', 'Cabin_Num']
correlation_matrix = train_df[correlation_cols].corr()

plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, 
            square=True, linewidths=1, cbar_kws={"shrink": 0.8})
plt.title('æ•°å€¤å¤‰æ•°ã®ç›¸é–¢è¡Œåˆ—', fontsize=16, weight='bold', pad=20)
plt.tight_layout()
plt.show()


# ## 6ï¸âƒ£ ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã®æ´»ç”¨
# PassengerIdã®ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã¯éå¸¸ã«é‡è¦ã§ã™ã€‚åŒã˜ã‚°ãƒ«ãƒ¼ãƒ—ã®äººã¯ä¸€ç·’ã«æ—…è¡Œã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒé«˜ãã€åŒã˜ã‚ˆã†ãªç‰¹æ€§ã‚’æŒã¤ã¯ãšã§ã™ã€‚

# In[14]:


def create_group_features(train_df, test_df):
    """
    ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‹ã‚‰ç‰¹å¾´é‡ã‚’ä½œæˆ
    """
    # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦ã‚°ãƒ«ãƒ¼ãƒ—çµ±è¨ˆã‚’è¨ˆç®—
    all_data = pd.concat([train_df, test_df], axis=0, ignore_index=True)

    # ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚º
    group_size = all_data.groupby('GroupId').size()
    train_df['GroupSize'] = train_df['GroupId'].map(group_size)
    test_df['GroupSize'] = test_df['GroupId'].map(group_size)

    # å˜ç‹¬æ—…è¡Œè€…ã‹ã©ã†ã‹
    train_df['IsAlone'] = (train_df['GroupSize'] == 1).astype(int)
    test_df['IsAlone'] = (test_df['GroupSize'] == 1).astype(int)

    # ãƒ•ã‚¡ãƒŸãƒªãƒ¼ã‚µã‚¤ã‚ºï¼ˆåŒã˜å§“ï¼‰
    family_size = all_data.groupby('LastName').size()
    train_df['FamilySize'] = train_df['LastName'].map(family_size).fillna(1)
    test_df['FamilySize'] = test_df['LastName'].map(family_size).fillna(1)

    # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®å¹³å‡å¹´é½¢
    group_age_mean = all_data.groupby('GroupId')['Age'].mean()
    train_df['Group_Age_Mean'] = train_df['GroupId'].map(group_age_mean)
    test_df['Group_Age_Mean'] = test_df['GroupId'].map(group_age_mean)

    # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®ç·æ”¯å‡ºé¡
    group_spending = all_data.groupby('GroupId')['TotalSpending'].sum()
    train_df['Group_TotalSpending'] = train_df['GroupId'].map(group_spending)
    test_df['Group_TotalSpending'] = test_df['GroupId'].map(group_spending)

    # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§æœ€ã‚‚å¤šã„HomePlanet
    group_homeplanet = all_data.groupby('GroupId')['HomePlanet'].apply(
        lambda x: x.mode()[0] if len(x.mode()) > 0 else np.nan
    )
    train_df['Group_HomePlanet'] = train_df['GroupId'].map(group_homeplanet)
    test_df['Group_HomePlanet'] = test_df['GroupId'].map(group_homeplanet)

    # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã§æœ€ã‚‚å¤šã„Destination
    group_destination = all_data.groupby('GroupId')['Destination'].apply(
        lambda x: x.mode()[0] if len(x.mode()) > 0 else np.nan
    )
    train_df['Group_Destination'] = train_df['GroupId'].map(group_destination)
    test_df['Group_Destination'] = test_df['GroupId'].map(group_destination)

    return train_df, test_df

train_df, test_df = create_group_features(train_df, test_df)
print("âœ… ã‚°ãƒ«ãƒ¼ãƒ—ç‰¹å¾´é‡ä½œæˆå®Œäº†")


# ### ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã®åˆ†å¸ƒã‚’ç¢ºèª

# In[15]:


# ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã®åˆ†å¸ƒ
fig, axes = plt.subplots(1, 2, figsize=(16, 5))

train_df['GroupSize'].value_counts().sort_index().plot(kind='bar', ax=axes[0], color='teal')
axes[0].set_title('ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã®åˆ†å¸ƒ', fontsize=14, weight='bold')
axes[0].set_xlabel('ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚º')
axes[0].set_ylabel('äººæ•°')

# ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã¨Transportedã®é–¢ä¿‚
group_transported = train_df.groupby('GroupSize')['Transported'].mean()
group_transported.plot(kind='bar', ax=axes[1], color='steelblue')
axes[1].set_title('ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã”ã¨ã®Transportedç‡', fontsize=14, weight='bold')
axes[1].set_xlabel('ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚º')
axes[1].set_ylabel('Transportedç‡')
axes[1].axhline(y=0.5, color='red', linestyle='--', label='50%')
axes[1].legend()

plt.tight_layout()
plt.show()


# ## 7ï¸âƒ£ æ¬ æå€¤ã®å‡¦ç†
# ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’æ´»ç”¨ã—ã¦ã€ã‚ˆã‚Šè³¢ãæ¬ æå€¤ã‚’åŸ‹ã‚ã¾ã™ã€‚

# In[16]:


def smart_fill_missing(df):
    """
    ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’æ´»ç”¨ã—ãŸæ¬ æå€¤å‡¦ç†
    """
    # HomePlanet: ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã§åŸ‹ã‚ã‚‹ â†’ æœ€é »å€¤
    df['HomePlanet'] = df['HomePlanet'].fillna(df['Group_HomePlanet'])
    df['HomePlanet'] = df['HomePlanet'].fillna(df['HomePlanet'].mode()[0])

    # Destination: ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã§åŸ‹ã‚ã‚‹ â†’ æœ€é »å€¤
    df['Destination'] = df['Destination'].fillna(df['Group_Destination'])
    df['Destination'] = df['Destination'].fillna(df['Destination'].mode()[0])

    # Age: ã‚°ãƒ«ãƒ¼ãƒ—å¹³å‡ â†’ å…¨ä½“ä¸­å¤®å€¤
    df['Age'] = df['Age'].fillna(df['Group_Age_Mean'])
    df['Age'] = df['Age'].fillna(df['Age'].median())

    # CryoSleep: æ”¯å‡ºãŒå…¨ã¦0ãªã‚‰Trueã€ãã‚Œä»¥å¤–ã¯æœ€é »å€¤
    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']
    df['CryoSleep'] = df.apply(
        lambda row: True if pd.isna(row['CryoSleep']) and (row[spending_cols].fillna(0) == 0).all() 
        else row['CryoSleep'], axis=1
    )
    df['CryoSleep'] = df['CryoSleep'].fillna(df['CryoSleep'].mode()[0])

    # VIP: æœ€é »å€¤ã§åŸ‹ã‚ã‚‹
    df['VIP'] = df['VIP'].fillna(df['VIP'].mode()[0])

    # æ”¯å‡ºé …ç›®: 0ã§åŸ‹ã‚ã‚‹ï¼ˆæ¬ æ=ä½¿ã£ã¦ã„ãªã„ï¼‰
    for col in spending_cols:
        df[col] = df[col].fillna(0)

    # TotalSpendingã‚’å†è¨ˆç®—
    df['TotalSpending'] = df[spending_cols].sum(axis=1)

    # Cabiné–¢é€£
    df['Cabin_Deck'] = df['Cabin_Deck'].fillna('Unknown')
    df['Cabin_Side'] = df['Cabin_Side'].fillna('Unknown')
    df['Cabin_Num'] = df['Cabin_Num'].fillna(df['Cabin_Num'].median())

    return df

train_df = smart_fill_missing(train_df)
test_df = smart_fill_missing(test_df)

print("âœ… æ¬ æå€¤å‡¦ç†å®Œäº†")
print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ®‹ã‚Šæ¬ æå€¤: {train_df.isnull().sum().sum()}")
print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ®‹ã‚Šæ¬ æå€¤: {test_df.isnull().sum().sum()}")


# ## 8ï¸âƒ£ é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
# ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ–°ã—ã„ç‰¹å¾´é‡ã‚’ä½œæˆã—ã¾ã™ã€‚

# In[17]:


def create_advanced_features(df):
    """
    é«˜åº¦ãªç‰¹å¾´é‡ã‚’ä½œæˆï¼ˆNaNå‡¦ç†ã‚’å¼·åŒ–ï¼‰
    """
    spending_cols = ['RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']

    # å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—
    df['AgeGroup'] = pd.cut(df['Age'], bins=[0, 12, 18, 25, 35, 50, 100], 
                            labels=['Child', 'Teen', 'YoungAdult', 'Adult', 'MiddleAge', 'Senior'])
    df['AgeGroup'] = df['AgeGroup'].astype(str)

    # æ”¯å‡ºãŒã‚ã‚‹ã‹ã©ã†ã‹
    df['HasSpending'] = (df['TotalSpending'] > 0).astype(int)

    # å„æ–½è¨­ã®åˆ©ç”¨æœ‰ç„¡
    for col in spending_cols:
        df[f'{col}_Used'] = (df[col] > 0).astype(int)

    # åˆ©ç”¨æ–½è¨­æ•°
    df['NumFacilitiesUsed'] = df[[f'{col}_Used' for col in spending_cols]].sum(axis=1)

    # CryoSleepã¨æ”¯å‡ºã®çŸ›ç›¾
    df['CryoSleep_Spending_Conflict'] = (
        ((df['CryoSleep'] == True) & (df['TotalSpending'] > 0)) |
        ((df['CryoSleep'] == False) & (df['TotalSpending'] == 0))
    ).astype(int)

    # å¹´é½¢ã‚ãŸã‚Šã®æ”¯å‡º
    df['SpendingPerAge'] = df['TotalSpending'] / (df['Age'] + 1)

    # é«˜æ”¯å‡ºè€…ãƒ•ãƒ©ã‚°
    df['HighSpender'] = (df['TotalSpending'] > df['TotalSpending'].quantile(0.75)).astype(int)

    # ãƒ‡ãƒƒã‚­ãŒç«¯ã‹ã©ã†ã‹
    edge_decks = ['A', 'T', 'G']
    df['IsEdgeDeck'] = df['Cabin_Deck'].isin(edge_decks).astype(int)

    # æ”¯å‡ºã®æ¨™æº–åå·®ï¼ˆæ”¯å‡ºã®ã°ã‚‰ã¤ãï¼‰- NaNå¯¾ç­–
    df['SpendingStd'] = df[spending_cols].std(axis=1).fillna(0)

    # æœ€ã‚‚å¤šãä½¿ã£ãŸæ–½è¨­
    df['MaxSpendingCategory'] = df[spending_cols].idxmax(axis=1)

    # VIPã¨æ”¯å‡ºã®é–¢ä¿‚
    df['VIP_Spending_Ratio'] = df['TotalSpending'] * df['VIP'].astype(int)

    # ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã‚«ãƒ†ã‚´ãƒª
    df['GroupSizeCategory'] = pd.cut(df['GroupSize'], bins=[0, 1, 2, 4, 100], 
                                     labels=['Solo', 'Small', 'Medium', 'Large'])
    df['GroupSizeCategory'] = df['GroupSizeCategory'].astype(str)

    # å¹´é½¢ã¨CryoSleepã®ç›¸äº’ä½œç”¨
    df['Age_CryoSleep'] = df['Age'] * df['CryoSleep'].astype(int)

    # ãƒ‡ãƒƒã‚­ç•ªå·ã®åŒºé–“ - NaNå¯¾ç­–
    df['Cabin_Num_Group'] = pd.cut(df['Cabin_Num'], bins=10, labels=False)
    df['Cabin_Num_Group'] = df['Cabin_Num_Group'].fillna(-1).astype(int)

    # HomePlanetã¨Destinationã®çµ„ã¿åˆã‚ã›
    df['HomePlanet_Destination'] = df['HomePlanet'].astype(str) + '_' + df['Destination'].astype(str)

    return df

train_df = create_advanced_features(train_df)
test_df = create_advanced_features(test_df)

# ã‚°ãƒ«ãƒ¼ãƒ—é–¢é€£ç‰¹å¾´é‡ã®NaNå‡¦ç†ã‚’è¿½åŠ 
train_df['Group_Age_Mean'] = train_df['Group_Age_Mean'].fillna(train_df['Age'].median())
test_df['Group_Age_Mean'] = test_df['Group_Age_Mean'].fillna(test_df['Age'].median())

train_df['Group_TotalSpending'] = train_df['Group_TotalSpending'].fillna(0)
test_df['Group_TotalSpending'] = test_df['Group_TotalSpending'].fillna(0)

print("âœ… é«˜åº¦ãªç‰¹å¾´é‡ä½œæˆå®Œäº†")
print(f"\nä½œæˆã—ãŸç‰¹å¾´é‡:")
print("- AgeGroup: å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—")
print("- HasSpending: æ”¯å‡ºãŒã‚ã‚‹ã‹")
print("- NumFacilitiesUsed: åˆ©ç”¨æ–½è¨­æ•°")
print("- CryoSleep_Spending_Conflict: CryoSleepã¨æ”¯å‡ºã®çŸ›ç›¾")
print("- SpendingPerAge: å¹´é½¢ã‚ãŸã‚Šã®æ”¯å‡º")
print("- ãã®ä»–å¤šæ•°...")


# ### æ–°ã—ã„ç‰¹å¾´é‡ã®å¯è¦–åŒ–

# In[18]:


# å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ã¨Transportedã®é–¢ä¿‚
fig, axes = plt.subplots(1, 2, figsize=(16, 5))

age_group_order = ['Child', 'Teen', 'YoungAdult', 'Adult', 'MiddleAge', 'Senior']
age_transported = train_df.groupby('AgeGroup')['Transported'].mean().reindex(age_group_order)
age_transported.plot(kind='bar', ax=axes[0], color='teal')
axes[0].set_title('å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®Transportedç‡', fontsize=14, weight='bold')
axes[0].set_ylabel('Transportedç‡')
axes[0].axhline(y=0.5, color='red', linestyle='--', label='50%')
axes[0].legend()
axes[0].set_xticklabels(age_group_order, rotation=45)

# åˆ©ç”¨æ–½è¨­æ•°ã¨Transportedã®é–¢ä¿‚
facilities_transported = train_df.groupby('NumFacilitiesUsed')['Transported'].mean()
facilities_transported.plot(kind='bar', ax=axes[1], color='purple')
axes[1].set_title('åˆ©ç”¨æ–½è¨­æ•°ã”ã¨ã®Transportedç‡', fontsize=14, weight='bold')
axes[1].set_xlabel('åˆ©ç”¨æ–½è¨­æ•°')
axes[1].set_ylabel('Transportedç‡')
axes[1].axhline(y=0.5, color='red', linestyle='--', label='50%')
axes[1].legend()

plt.tight_layout()
plt.show()


# ## 9ï¸âƒ£ ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°

# In[19]:


# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°
categorical_cols = [
    'HomePlanet', 'CryoSleep', 'Destination', 'VIP',
    'Cabin_Deck', 'Cabin_Side', 'AgeGroup', 'GroupSizeCategory',
    'MaxSpendingCategory', 'HomePlanet_Destination'
]

# Label Encoding
label_encoders = {}
for col in categorical_cols:
    le = LabelEncoder()
    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’çµåˆã—ã¦fit
    combined = pd.concat([train_df[col].astype(str), test_df[col].astype(str)], axis=0)
    le.fit(combined)
    train_df[col] = le.transform(train_df[col].astype(str))
    test_df[col] = le.transform(test_df[col].astype(str))
    label_encoders[col] = le

print("âœ… ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å®Œäº†")


# ## ğŸ”Ÿ ç‰¹å¾´é‡ã®é¸æŠã¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™

# In[20]:


# ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ
feature_columns = [
    # åŸºæœ¬çš„ãªã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«
    'HomePlanet', 'CryoSleep', 'Destination', 'VIP',
    'Cabin_Deck', 'Cabin_Side', 'AgeGroup',

    # åŸºæœ¬çš„ãªæ•°å€¤
    'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',
    'TotalSpending', 'Cabin_Num',

    # ã‚°ãƒ«ãƒ¼ãƒ—é–¢é€£
    'GroupSize', 'IsAlone', 'FamilySize', 'Group_Age_Mean', 'Group_TotalSpending',

    # æ”¯å‡ºé–¢é€£
    'HasSpending', 'NumFacilitiesUsed', 'SpendingPerAge', 'HighSpender',
    'RoomService_Used', 'FoodCourt_Used', 'ShoppingMall_Used', 'Spa_Used', 'VRDeck_Used',
    'SpendingStd', 'MaxSpendingCategory', 'VIP_Spending_Ratio',

    # ãã®ä»–
    'CryoSleep_Spending_Conflict', 'IsEdgeDeck', 'GroupSizeCategory',
    'Age_CryoSleep', 'Cabin_Num_Group', 'HomePlanet_Destination'
]

print(f"ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã®æ•°: {len(feature_columns)}")

# ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®åˆ†é›¢
X = train_df[feature_columns]
y = train_df['Transported']
X_test = test_df[feature_columns]

# æœ€çµ‚NaNãƒã‚§ãƒƒã‚¯
print(f"\nã€æœ€çµ‚NaNãƒã‚§ãƒƒã‚¯ - è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã€‘")
print(f"æ®‹ã‚ŠNaNæ•°: {X.isnull().sum().sum()}")
if X.isnull().sum().sum() > 0:
    print("NaNãŒæ®‹ã£ã¦ã„ã‚‹åˆ—:")
    print(X.isnull().sum()[X.isnull().sum() > 0])

print(f"\nã€æœ€çµ‚NaNãƒã‚§ãƒƒã‚¯ - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã€‘")
print(f"æ®‹ã‚ŠNaNæ•°: {X_test.isnull().sum().sum()}")
if X_test.isnull().sum().sum() > 0:
    print("NaNãŒæ®‹ã£ã¦ã„ã‚‹åˆ—:")
    print(X_test.isnull().sum()[X_test.isnull().sum() > 0])

print(f"\nX shape: {X.shape}")
print(f"y shape: {y.shape}")
print(f"X_test shape: {X_test.shape}")


# ## 1ï¸âƒ£1ï¸âƒ£ ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ã¨è©•ä¾¡
# ### ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«ã¤ã„ã¦
# ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆäº¤å·®æ¤œè¨¼ï¼‰ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’ä¿¡é ¼æ€§é«˜ãè©•ä¾¡ã™ã‚‹æ‰‹æ³•ã§ã™ã€‚
# ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°ã®åˆ†å‰²ï¼ˆFoldï¼‰ã«åˆ†ã‘ã€ãã‚Œãã‚Œã‚’æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ã„ã¾ã™ã€‚
# ã“ã“ã§ã¯5åˆ†å‰²ï¼ˆ5-Foldï¼‰ã‚’ä½¿ç”¨ã—ã€ã‚ˆã‚Šå®‰å®šã—ãŸè©•ä¾¡ã‚’è¡Œã„ã¾ã™ã€‚

# In[21]:


def evaluate_model_cv(model, X, y, cv=5, model_name="Model"):
    """
    Stratified K-Fold Cross Validationã§ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
    """
    skf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=RANDOM_STATE)
    scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')

    print(f"\n{'='*60}")
    print(f"{model_name}")
    print(f"{'='*60}")
    print(f"å„Foldã®CV Score: {scores}")
    print(f"å¹³å‡CV Score: {scores.mean():.4f} (+/- {scores.std() * 2:.4f})")

    return scores.mean(), scores.std()


# ### 11.1 Random Forest

# In[22]:


rf_model = RandomForestClassifier(
    n_estimators=300,
    max_depth=12,
    min_samples_split=8,
    min_samples_leaf=3,
    max_features='sqrt',
    random_state=RANDOM_STATE,
    n_jobs=-1
)

rf_mean, rf_std = evaluate_model_cv(rf_model, X, y, cv=5, model_name="Random Forest")

# å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
rf_model.fit(X, y)
print("âœ… Random Forest å­¦ç¿’å®Œäº†")


# ### 11.2 XGBoost
# XGBoostã¯å‹¾é…ãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ã®æ”¹è‰¯ç‰ˆã§ã€Kaggleã‚³ãƒ³ãƒšã§éå¸¸ã«äººæ°—ã®ã‚ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚

# In[23]:


xgb_model = xgb.XGBClassifier(
    n_estimators=300,
    max_depth=6,
    learning_rate=0.05,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=RANDOM_STATE,
    eval_metric='logloss',
    n_jobs=-1
)

xgb_mean, xgb_std = evaluate_model_cv(xgb_model, X, y, cv=5, model_name="XGBoost")

# å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
xgb_model.fit(X, y)
print("âœ… XGBoost å­¦ç¿’å®Œäº†")


# ### 11.3 LightGBM
# LightGBMã¯MicrosoftãŒé–‹ç™ºã—ãŸè»½é‡ã§é«˜é€Ÿãªãƒ–ãƒ¼ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚

# In[24]:


lgb_model = lgb.LGBMClassifier(
    n_estimators=300,
    max_depth=8,
    learning_rate=0.05,
    num_leaves=31,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=RANDOM_STATE,
    n_jobs=-1,
    verbose=-1
)

lgb_mean, lgb_std = evaluate_model_cv(lgb_model, X, y, cv=5, model_name="LightGBM")

# å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
lgb_model.fit(X, y)
print("âœ… LightGBM å­¦ç¿’å®Œäº†")


# ### 11.4 Gradient Boosting

# In[25]:


gb_model = GradientBoostingClassifier(
    n_estimators=300,
    max_depth=5,
    learning_rate=0.05,
    subsample=0.8,
    random_state=RANDOM_STATE
)

gb_mean, gb_std = evaluate_model_cv(gb_model, X, y, cv=5, model_name="Gradient Boosting")

# å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
gb_model.fit(X, y)
print("âœ… Gradient Boosting å­¦ç¿’å®Œäº†")


# ### 11.5 Logistic Regressionï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä»˜ãï¼‰
# Logistic Regressionã¯ç·šå½¢ãƒ¢ãƒ‡ãƒ«ãªã®ã§ã€æ•°å€¤å¤‰æ•°ã‚’ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚

# In[26]:


# æ•°å€¤å¤‰æ•°ã®ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
numerical_features = [
    'Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck',
    'TotalSpending', 'Cabin_Num', 'GroupSize', 'FamilySize',
    'Group_Age_Mean', 'Group_TotalSpending', 'NumFacilitiesUsed',
    'SpendingPerAge', 'SpendingStd', 'VIP_Spending_Ratio', 'Age_CryoSleep'
]

scaler = StandardScaler()
X_scaled = X.copy()
X_test_scaled = X_test.copy()

X_scaled[numerical_features] = scaler.fit_transform(X[numerical_features])
X_test_scaled[numerical_features] = scaler.transform(X_test[numerical_features])

lr_model = LogisticRegression(
    C=1.0,
    max_iter=1000,
    random_state=RANDOM_STATE
)

lr_mean, lr_std = evaluate_model_cv(lr_model, X_scaled, y, cv=5, model_name="Logistic Regression")

# å…¨ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
lr_model.fit(X_scaled, y)
print("âœ… Logistic Regression å­¦ç¿’å®Œäº†")


# ### 11.6 ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ

# In[27]:


# ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ
model_comparison = pd.DataFrame({
    'ãƒ¢ãƒ‡ãƒ«': ['Random Forest', 'XGBoost', 'LightGBM', 'Gradient Boosting', 'Logistic Regression'],
    'CVå¹³å‡ã‚¹ã‚³ã‚¢': [rf_mean, xgb_mean, lgb_mean, gb_mean, lr_mean],
    'CVæ¨™æº–åå·®': [rf_std, xgb_std, lgb_std, gb_std, lr_std]
}).sort_values('CVå¹³å‡ã‚¹ã‚³ã‚¢', ascending=False)

print("\n" + "="*70)
print("ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒï¼ˆStratified 5-Fold Cross Validationï¼‰")
print("="*70)
print(model_comparison.to_string(index=False))
print("="*70)

# å¯è¦–åŒ–
fig, ax = plt.subplots(figsize=(14, 7))
x_pos = np.arange(len(model_comparison))
bars = ax.bar(x_pos, model_comparison['CVå¹³å‡ã‚¹ã‚³ã‚¢'], 
               yerr=model_comparison['CVæ¨™æº–åå·®'], 
               capsize=5, color='steelblue', alpha=0.8, edgecolor='black', linewidth=1.5)

ax.set_xlabel('ãƒ¢ãƒ‡ãƒ«', fontsize=13, weight='bold')
ax.set_ylabel('CVå¹³å‡ã‚¹ã‚³ã‚¢', fontsize=13, weight='bold')
ax.set_title('ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦æ¯”è¼ƒï¼ˆ5-Fold Cross Validationï¼‰', fontsize=16, weight='bold', pad=20)
ax.set_xticks(x_pos)
ax.set_xticklabels(model_comparison['ãƒ¢ãƒ‡ãƒ«'], rotation=15, ha='right')
ax.set_ylim([0.78, 0.83])
ax.axhline(y=0.80, color='red', linestyle='--', linewidth=2, label='ç›®æ¨™: 0.80')
ax.legend(fontsize=11)
ax.grid(axis='y', alpha=0.3)

# ãƒãƒ¼ã®ä¸Šã«æ•°å€¤ã‚’è¡¨ç¤º
for i, (bar, score) in enumerate(zip(bars, model_comparison['CVå¹³å‡ã‚¹ã‚³ã‚¢'])):
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width()/2., height + 0.003,
            f'{score:.4f}', ha='center', va='bottom', fontsize=11, weight='bold')

plt.tight_layout()
plt.show()


# ### 11.7 ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆRandom Forestã®å ´åˆï¼‰

# In[28]:


# ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’è¡¨ç¤º
feature_importance = pd.DataFrame({
    'ç‰¹å¾´é‡': feature_columns,
    'é‡è¦åº¦': rf_model.feature_importances_
}).sort_values('é‡è¦åº¦', ascending=False)

# ãƒˆãƒƒãƒ—20ã®ç‰¹å¾´é‡ã‚’å¯è¦–åŒ–
plt.figure(figsize=(12, 10))
top_features = feature_importance.head(20)
plt.barh(range(len(top_features)), top_features['é‡è¦åº¦'], color='steelblue', edgecolor='black')
plt.yticks(range(len(top_features)), top_features['ç‰¹å¾´é‡'])
plt.xlabel('é‡è¦åº¦', fontsize=12, weight='bold')
plt.title('ç‰¹å¾´é‡ã®é‡è¦åº¦ï¼ˆRandom Forest - ãƒˆãƒƒãƒ—20ï¼‰', fontsize=14, weight='bold', pad=15)
plt.gca().invert_yaxis()
plt.grid(axis='x', alpha=0.3)
plt.tight_layout()
plt.show()

print("\nã€ãƒˆãƒƒãƒ—15ã®é‡è¦ãªç‰¹å¾´é‡ã€‘")
print(feature_importance.head(15).to_string(index=False))


# ## 1ï¸âƒ£2ï¸âƒ£ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’
# è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šå®‰å®šã—ãŸäºˆæ¸¬ã‚’å¾—ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
# ### 12.1 å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬

# In[29]:


# å„ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
pred_rf = rf_model.predict(X_test)
pred_xgb = xgb_model.predict(X_test)
pred_lgb = lgb_model.predict(X_test)
pred_gb = gb_model.predict(X_test)
pred_lr = lr_model.predict(X_test_scaled)

print("âœ… å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å®Œäº†")


# ### 12.2 é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
# CVã‚¹ã‚³ã‚¢ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã«å¤§ããªé‡ã¿ã‚’ä¸ãˆã¾ã™ã€‚

# In[30]:


# CVã‚¹ã‚³ã‚¢ã«åŸºã¥ãé‡ã¿ï¼ˆã‚¹ã‚³ã‚¢ãŒé«˜ã„ãƒ¢ãƒ‡ãƒ«ã«å¤§ããªé‡ã¿ï¼‰
weights = np.array([rf_mean, xgb_mean, lgb_mean, gb_mean, lr_mean])
weights = weights / weights.sum()  # æ­£è¦åŒ–

print("\nã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®é‡ã¿ã€‘")
for model_name, weight in zip(['Random Forest', 'XGBoost', 'LightGBM', 'Gradient Boosting', 'Logistic Regression'], weights):
    print(f"{model_name:25s}: {weight:.4f}")

# é‡ã¿ä»˜ãå¹³å‡
ensemble_pred = (
    pred_rf.astype(int) * weights[0] +
    pred_xgb.astype(int) * weights[1] +
    pred_lgb.astype(int) * weights[2] +
    pred_gb.astype(int) * weights[3] +
    pred_lr.astype(int) * weights[4]
)

ensemble_pred_final = (ensemble_pred >= 0.5)

print("\nâœ… é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Œäº†")


# ### 12.3 å¤šæ•°æ±ºã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«

# In[31]:


# å¤šæ•°æ±ºï¼ˆ5ã¤ã®ãƒ¢ãƒ‡ãƒ«ã§3ã¤ä»¥ä¸ŠãŒTrueãªã‚‰Trueï¼‰
voting_pred = (
    pred_rf.astype(int) +
    pred_xgb.astype(int) +
    pred_lgb.astype(int) +
    pred_gb.astype(int) +
    pred_lr.astype(int)
) >= 3

print("âœ… å¤šæ•°æ±ºã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Œäº†")


# ### 12.4 ãƒˆãƒƒãƒ—3ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«

# In[32]:


# ãƒˆãƒƒãƒ—3ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆCVã‚¹ã‚³ã‚¢ãŒé«˜ã„é †ï¼‰
top3_indices = np.argsort(weights)[-3:]  # æœ€ã‚‚é«˜ã„3ã¤
top3_preds = [pred_rf, pred_xgb, pred_lgb, pred_gb, pred_lr]
top3_selected = [top3_preds[i] for i in top3_indices]
top3_names = [['Random Forest', 'XGBoost', 'LightGBM', 'Gradient Boosting', 'Logistic Regression'][i] for i in top3_indices]

print(f"\nãƒˆãƒƒãƒ—3ãƒ¢ãƒ‡ãƒ«: {top3_names}")

# ãƒˆãƒƒãƒ—3ã®å¤šæ•°æ±º
top3_voting = (
    top3_selected[0].astype(int) +
    top3_selected[1].astype(int) +
    top3_selected[2].astype(int)
) >= 2

print("âœ… ãƒˆãƒƒãƒ—3ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Œäº†")


# ## 1ï¸âƒ£3ï¸âƒ£ æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ

# In[33]:


# 1. XGBoostå˜ç‹¬
submission_xgb = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Transported': pred_xgb
})
submission_xgb.to_csv('submission_xgb.csv', index=False)
print("âœ… submission_xgb.csv ä½œæˆå®Œäº†")

# 2. LightGBMå˜ç‹¬
submission_lgb = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Transported': pred_lgb
})
submission_lgb.to_csv('submission_lgb.csv', index=False)
print("âœ… submission_lgb.csv ä½œæˆå®Œäº†")

# 3. é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
submission_weighted = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Transported': ensemble_pred_final
})
submission_weighted.to_csv('submission_weighted_ensemble.csv', index=False)
print("âœ… submission_weighted_ensemble.csv ä½œæˆå®Œäº†")

# 4. å¤šæ•°æ±ºã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
submission_voting = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Transported': voting_pred
})
submission_voting.to_csv('submission_voting.csv', index=False)
print("âœ… submission_voting.csv ä½œæˆå®Œäº†")

# 5. ãƒˆãƒƒãƒ—3ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
submission_top3 = pd.DataFrame({
    'PassengerId': test_df['PassengerId'],
    'Transported': top3_voting
})
submission_top3.to_csv('submission_top3.csv', index=False)
print("âœ… submission_top3.csv ä½œæˆå®Œäº†")


# ## 1ï¸âƒ£4ï¸âƒ£ äºˆæ¸¬çµæœã®ç¢ºèª

# In[34]:


print("\n" + "="*70)
print("å„æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®äºˆæ¸¬åˆ†å¸ƒ")
print("="*70)
print(f"XGBoostå˜ç‹¬          : True={pred_xgb.sum():4d}, False={len(pred_xgb)-pred_xgb.sum():4d}")
print(f"LightGBMå˜ç‹¬         : True={pred_lgb.sum():4d}, False={len(pred_lgb)-pred_lgb.sum():4d}")
print(f"é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« : True={ensemble_pred_final.sum():4d}, False={len(ensemble_pred_final)-ensemble_pred_final.sum():4d}")
print(f"å¤šæ•°æ±ºã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«   : True={voting_pred.sum():4d}, False={len(voting_pred)-voting_pred.sum():4d}")
print(f"ãƒˆãƒƒãƒ—3ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«  : True={top3_voting.sum():4d}, False={len(top3_voting)-top3_voting.sum():4d}")
print("="*70)

# ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
print("\nã€äºˆæ¸¬çµæœã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆé‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼‰ã€‘")
print(submission_weighted.head(20))


# ## ğŸ¯ ã¾ã¨ã‚
# ### å­¦ã‚“ã ã“ã¨
# 1. **ãƒ‡ãƒ¼ã‚¿ã®æ¢ç´¢ã¨ç†è§£**
#    - æ¬ æå€¤ã®ç¢ºèªã¨é©åˆ‡ãªå‡¦ç†æ–¹æ³•
#    - ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã¨æ•°å€¤å¤‰æ•°ã®é–¢ä¿‚åˆ†æ
#    - ã‚°ãƒ©ãƒ•ã«ã‚ˆã‚‹å¯è¦–åŒ–
# 2. **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**
#    - PassengerIdã€Cabinã€Nameã‹ã‚‰ã®æƒ…å ±æŠ½å‡º
#    - ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã®æ´»ç”¨ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚ºã€ã‚°ãƒ«ãƒ¼ãƒ—å†…çµ±è¨ˆãªã©ï¼‰
#    - ç›¸äº’ä½œç”¨ç‰¹å¾´é‡ã®ä½œæˆ
#    - 43å€‹ã®ç‰¹å¾´é‡ã‚’ä½¿ç”¨
# 3. **æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«**
#    - Random Forestã€XGBoostã€LightGBMã€Gradient Boostingã€Logistic Regression
#    - Stratified K-Fold Cross Validationã«ã‚ˆã‚‹è©•ä¾¡
#    - ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒã¨é¸æŠ
# 4. **ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’**
#    - é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆCVã‚¹ã‚³ã‚¢ã«åŸºã¥ãï¼‰
#    - å¤šæ•°æ±º
#    - ãƒˆãƒƒãƒ—ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›
# ---
# ### æå‡ºã®æ¨å¥¨é †åº
# 1. **submission_weighted_ensemble.csv** - æœ€åˆã«è©¦ã™
# 2. **submission_xgb.csv** ã¾ãŸã¯ **submission_lgb.csv** - å˜ä¸€ãƒ¢ãƒ‡ãƒ«ã§æœ€é«˜æ€§èƒ½
# 3. **submission_voting.csv** - å¤šæ•°æ±ºã«ã‚ˆã‚‹å®‰å®šã—ãŸäºˆæ¸¬
# 4. **submission_top3.csv** - ãƒˆãƒƒãƒ—3ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›
# è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æå‡ºã—ã¦ã‚¹ã‚³ã‚¢ã‚’æ¯”è¼ƒã—ã€æœ€ã‚‚è‰¯ã„ã‚‚ã®ã‚’é¸ã³ã¾ã—ã‚‡ã†ï¼
# ---
# ### ã•ã‚‰ãªã‚‹æ”¹å–„ã®ãƒ’ãƒ³ãƒˆ
# 1. **ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**
#    - GridSearchCVã‚„RandomizedSearchCVã‚’ä½¿ç”¨
#    - Optunaãªã©ã®è‡ªå‹•æœ€é©åŒ–ãƒ„ãƒ¼ãƒ«
# 2. **ç‰¹å¾´é‡é¸æŠ**
#    - é‡è¦åº¦ã®ä½ã„ç‰¹å¾´é‡ã‚’å‰Šé™¤
#    - RFEï¼ˆRecursive Feature Eliminationï¼‰
# 3. **ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°**
#    - ç¬¬1å±¤ã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã‚’ä½¿ã£ã¦ç¬¬2å±¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
# 4. **å¤–ã‚Œå€¤å‡¦ç†**
#    - æ”¯å‡ºé¡ã®æ¥µç«¯ãªå€¤ã‚’å‡¦ç†
# ---
# **é ‘å¼µã£ã¦ãã ã•ã„ï¼ãƒ–ãƒ­ãƒ³ã‚ºãƒ¡ãƒ€ãƒ«ç²å¾—ã‚’ç›®æŒ‡ã—ã¾ã—ã‚‡ã†ï¼ğŸš€âœ¨**

# ---
# # ğŸ“š å­¦ç¿’ã®ã¾ã¨ã‚
# ## ğŸ¯ æœ€ã‚‚é‡è¦ã ã£ãŸç™ºè¦‹ãƒˆãƒƒãƒ—5
# ### 1. ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã®å¾¹åº•æ´»ç”¨ â­â­â­â­â­
# **åŠ¹æœ**: ã‚¹ã‚³ã‚¢ +0.01ã€œ0.02
# PassengerIdã‹ã‚‰æŠ½å‡ºã—ãŸGroupIdã‚’ä½¿ã£ã¦ï¼š
# - ã‚°ãƒ«ãƒ¼ãƒ—å†…çµ±è¨ˆï¼ˆå¹³å‡å¹´é½¢ã€ç·æ”¯å‡ºãªã©ï¼‰
# - ã‚°ãƒ«ãƒ¼ãƒ—å†…æœ€é »å€¤ã§æ¬ æå€¤ã‚’åŸ‹ã‚ã‚‹
# - ã‚°ãƒ«ãƒ¼ãƒ—ã‚µã‚¤ã‚º
# **ã“ã‚ŒãŒæœ€å¤§ã®å‹å› ã§ã—ãŸï¼**
# ### 2. CryoSleepã¨æ”¯å‡ºã®é–¢ä¿‚ â­â­â­â­
# **ç™ºè¦‹**: CryoSleep=Trueã®äººã¯æ”¯å‡ºãŒ0
# ã“ã®é–¢ä¿‚ã‚’ä½¿ã£ã¦ï¼š
# - æ¬ æå€¤ã®æ¨å®š
# - çŸ›ç›¾ãƒ•ãƒ©ã‚°ã®ä½œæˆ
# - ç‰¹å¾´é‡ã®ç›¸äº’ä½œç”¨
# ### 3. LightGBMã®å®‰å®šæ€§ â­â­â­â­
# **ç†ç”±**:
# - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«éˆæ„Ÿ
# - éå­¦ç¿’ã—ã«ãã„
# - XGBoostã‚ˆã‚Šå®‰å®š
# åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ååˆ†ãªæ€§èƒ½ãŒå‡ºã¾ã—ãŸã€‚
# ### 4. ã‚·ãƒ³ãƒ—ãƒ«ã•ã®å‹åˆ© â­â­â­
# **çµæœ**:
# - 38ç‰¹å¾´é‡: 0.80336
# - 50ç‰¹å¾´é‡: 0.80523
# - å·®ã¯ã‚ãšã‹ +0.00187
# è¤‡é›‘ãªç‰¹å¾´é‡ã‚ˆã‚Šã€**æœ¬è³ªçš„ãªç‰¹å¾´é‡**ãŒé‡è¦ã€‚
# ### 5. Cabinï¼ˆãƒ‡ãƒƒã‚­ãƒ»ã‚µã‚¤ãƒ‰ï¼‰ã®é‡è¦æ€§ â­â­â­
# ãƒ‡ãƒƒã‚­ã«ã‚ˆã£ã¦è»¢é€ç‡ãŒå¤§ããç•°ãªã‚‹ï¼š
# - Bãƒ‡ãƒƒã‚­ã¨Gãƒ‡ãƒƒã‚­ã¯è»¢é€ç‡ãŒé«˜ã„
# - ã‚µã‚¤ãƒ‰ï¼ˆP/Sï¼‰ã‚‚å½±éŸ¿ã‚ã‚Š
# ---
# ## âŒ å¤±æ•—ã‹ã‚‰å­¦ã‚“ã ã“ã¨
# ### 1. Optunaã®éå­¦ç¿’
# **å•é¡Œ**: CVã‚¹ã‚³ã‚¢ 0.8123 â†’ å®Ÿéš› 0.80523 = **-0.007**
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«éåº¦ã«æœ€é©åŒ–ã•ã‚Œã¦æ±åŒ–æ€§èƒ½ãŒè½ã¡ãŸã€‚
# **æ•™è¨“**: åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ååˆ†ã€‚éåº¦ãªæœ€é©åŒ–ã¯é€†åŠ¹æœã€‚
# ### 2. ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã®æœŸå¾…å¤–ã‚Œ
# **çµæœ**: 0.79798ï¼ˆæœ€ä½ã‚¹ã‚³ã‚¢ï¼‰
# ç†è«–ä¸Šã¯å¼·åŠ›ã ãŒï¼š
# - è¨ˆç®—æ™‚é–“ãŒã‹ã‹ã‚‹
# - éå­¦ç¿’ãƒªã‚¹ã‚¯ãŒé«˜ã„
# - å˜ç´”ãªLightGBMã«è² ã‘ãŸ
# **æ•™è¨“**: è¤‡é›‘ â‰  é«˜æ€§èƒ½
# ### 3. æå‡ºãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
# **ãƒˆãƒ©ãƒ–ãƒ«**: Transportedåˆ—ã‚’æ•´æ•°ã§ä¿å­˜ â†’ ã‚¹ã‚³ã‚¢ 0.00
# **è§£æ±ºç­–**: `.astype(bool)`ã§å¿…ãšboolå‹ã«å¤‰æ›
# ```python
# 'Transported': pred.astype(bool)  # ã“ã‚Œå¿…é ˆï¼
# ```
# ### 4. è¤‡é›‘ãªç‰¹å¾´é‡ã®é™ç•Œ
# **è©¦ã—ãŸãŒåŠ¹æœè–„**:
# - AgeÂ²ã€AgeÂ³ï¼ˆéç·šå½¢æ€§ï¼‰
# - æ”¯å‡ºã®åã‚ŠæŒ‡æ¨™
# - éåº¦ãªç›¸äº’ä½œç”¨
# **æ•™è¨“**: ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã«åŸºã¥ãç‰¹å¾´é‡ > æ©Ÿæ¢°çš„ãªç‰¹å¾´é‡
# ---
# ## ğŸ’¡ åŠ¹æœçš„ã ã£ãŸç‰¹å¾´é‡ãƒˆãƒƒãƒ—10
# ç‰¹å¾´é‡ã®é‡è¦åº¦ã‹ã‚‰ï¼š
# 1. **SpendingStd** - æ”¯å‡ºã®æ¨™æº–åå·®
# 2. **MaxSpendingCategory** - æœ€ã‚‚å¤šãä½¿ã£ãŸæ–½è¨­
# 3. **TotalSpending** - ç·æ”¯å‡ºé¡
# 4. **SpendingPerAge** - å¹´é½¢ã‚ãŸã‚Šã®æ”¯å‡º
# 5. **NumFacilitiesUsed** - åˆ©ç”¨æ–½è¨­æ•°
# 6. **HasSpending** - æ”¯å‡ºãŒã‚ã‚‹ã‹
# 7. **FoodCourt** - ãƒ•ãƒ¼ãƒ‰ã‚³ãƒ¼ãƒˆæ”¯å‡º
# 8. **Cabin_Num** - éƒ¨å±‹ç•ªå·
# 9. **Spa** - ã‚¹ãƒ‘æ”¯å‡º
# 10. **ShoppingMall** - ã‚·ãƒ§ãƒƒãƒ”ãƒ³ã‚°ãƒ¢ãƒ¼ãƒ«æ”¯å‡º
# **å…±é€šç‚¹**: æ”¯å‡ºé–¢é€£ãŒå¤šã„ï¼
# ---
# ## ğŸ“ å­¦ç¿’ãƒ¬ãƒ™ãƒ«åˆ¥ã®ãƒã‚¤ãƒ³ãƒˆ
# ### åˆå¿ƒè€…å‘ã‘ ğŸŒ±
# **ã¾ãšç†è§£ã™ã¹ãã“ã¨**:
# 1. ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆï¼ˆ.describe(), .info()ï¼‰
# 2. æ¬ æå€¤ã®ç¢ºèªï¼ˆ.isnull().sum()ï¼‰
# 3. ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®åˆ†å¸ƒ
# 4. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®é–¢ä¿‚
# **å®Ÿè·µã‚¿ã‚¹ã‚¯**:
# - ã‚°ãƒ©ãƒ•ã‚’è¦‹ã¦å‚¾å‘ã‚’æ´ã‚€
# - ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰å§‹ã‚ã‚‹
# - ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§è©•ä¾¡
# ### ä¸­ç´šè€…å‘ã‘ ğŸŒ¿
# **æ·±æ˜ã‚Šã™ã¹ãã“ã¨**:
# 1. ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜ã®æ´»ç”¨ï¼ˆCryoSleepã€ã‚°ãƒ«ãƒ¼ãƒ—æ—…è¡Œï¼‰
# 2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆé›†ç´„ã€ç›¸äº’ä½œç”¨ï¼‰
# 3. è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒ
# 4. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•
# **å®Ÿè·µã‚¿ã‚¹ã‚¯**:
# - ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±ã‚’å¾¹åº•æ´»ç”¨
# - æ–°ã—ã„ç‰¹å¾´é‡ã‚’ä½œã£ã¦æ¤œè¨¼
# - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´
# ### ä¸Šç´šè€…å‘ã‘ ğŸŒ³
# **è¿½æ±‚ã™ã¹ãã“ã¨**:
# 1. éå­¦ç¿’ã¨ã®æˆ¦ã„ï¼ˆæ­£å‰‡åŒ–ã€ç‰¹å¾´é‡é¸æŠï¼‰
# 2. CVæˆ¦ç•¥ï¼ˆGroupKFoldæ¤œè¨ï¼‰
# 3. ãƒªãƒ¼ã‚¯æ¤œå‡ºã¨å¯¾ç­–
# 4. åŠ¹ç‡çš„ãªå®Ÿé¨“ç®¡ç†
# **å®Ÿè·µã‚¿ã‚¹ã‚¯**:
# - CVã‚¹ã‚³ã‚¢ã¨å®Ÿéš›ã®ã‚¹ã‚³ã‚¢ã®å·®ã‚’åˆ†æ
# - ç‰¹å¾´é‡ã®é‡è¦åº¦ã§é¸æŠ
# - ã‚ˆã‚Šæ±åŒ–æ€§èƒ½ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
# ---
# ## ğŸ“Š ã‚¹ã‚³ã‚¢æ¨ç§»ã¾ã¨ã‚
# ```
# é–‹å§‹æ™‚:
# â”œâ”€ åŸºæœ¬çš„ãªæå‡º: 0.70å°ï¼ˆæ¨å®šï¼‰
# â”‚
# ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±æ´»ç”¨:
# â”œâ”€ åˆå›LightGBM: 0.80336âœ…
# â”‚
# æœ€é©åŒ–:
# â”œâ”€ LightGBMæœ€é©åŒ–: 0.80523â­ â† æœ€é«˜ã‚¹ã‚³ã‚¢
# â”œâ”€ Ensembleæœ€é©åŒ–: 0.80500
# â”œâ”€ XGBoostæœ€é©åŒ–: 0.80266
# â””â”€ ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°: 0.79798 âŒ
# ```
# ---
# ## ğŸš€ ã•ã‚‰ãªã‚‹æ”¹å–„ã®ã‚¢ã‚¤ãƒ‡ã‚¢
# ### è©¦ã™ä¾¡å€¤ãŒé«˜ã„ï¼ˆæœŸå¾…: +0.002ã€œ0.005ï¼‰
# 1. **ç‰¹å¾´é‡é¸æŠ**
#    - é‡è¦åº¦ãƒˆãƒƒãƒ—30-35ã ã‘ä½¿ã†
#    - éå­¦ç¿’ã‚’æŠ‘ãˆã¦æ±åŒ–æ€§èƒ½å‘ä¸Š
# 2. **ã‚ˆã‚Šä¿å®ˆçš„ãªæ­£å‰‡åŒ–**
#    ```python
#    learning_rate=0.03  # 0.05ã‚ˆã‚Šä½ã
#    max_depth=5         # 8ã‚ˆã‚Šæµ…ã
#    ```
# 3. **GroupKFold**
#    - åŒã˜ã‚°ãƒ«ãƒ¼ãƒ—ãŒè¨“ç·´ã¨æ¤œè¨¼ã«åˆ†ã‹ã‚Œãªã„ã‚ˆã†ã«
#    - ã‚ˆã‚Šç¾å®Ÿçš„ãªCVè©•ä¾¡
# ### è©¦ã™ä¾¡å€¤ãŒä½ã„
# - âŒ ã•ã‚‰ãªã‚‹Optunaæœ€é©åŒ–
# - âŒ è¤‡é›‘ãªç‰¹å¾´é‡ã®è¿½åŠ 
# - âŒ ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°
# - âŒ éåº¦ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
# ---
# ## ğŸ† æœ€çµ‚çµè«–
# ### æˆåŠŸã®3æœ¬æŸ±
# 1. **ã‚°ãƒ«ãƒ¼ãƒ—æƒ…å ±** - PassengerIdã®å¾¹åº•æ´»ç”¨
# 2. **ã‚·ãƒ³ãƒ—ãƒ«ã•** - æœ¬è³ªçš„ãªç‰¹å¾´é‡ã«é›†ä¸­
# 3. **LightGBM** - å®‰å®šã—ãŸé«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«
# ### å­¦ã‚“ã æœ€å¤§ã®æ•™è¨“
# > **ã€Œè¤‡é›‘ã•ã‚ˆã‚Šã‚‚æœ¬è³ªã€**
# >
# > 50å€‹ã®ç‰¹å¾´é‡ã‚ˆã‚Šã€38å€‹ã®è‰¯è³ªãªç‰¹å¾´é‡ã€‚
# > Optunaã‚ˆã‚Šã€åŸºæœ¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€‚
# > ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚ˆã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ãªLightGBMã€‚
# ---
# ## ğŸ“– å‚è€ƒã«ãªã‚‹ãƒªã‚½ãƒ¼ã‚¹
# - [Kaggleå…¬å¼ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«](https://www.kaggle.com/learn)
# - [LightGBMãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://lightgbm.readthedocs.io/)
# - [ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å…¥é–€](https://www.kaggle.com/learn/feature-engineering)
# ---
# **ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ãŒçš†ã•ã‚“ã®Kaggleå­¦ç¿’ã«å½¹ç«‹ã¦ã°å¹¸ã„ã§ã™ï¼**
# **Happy Kaggling! ğŸš€âœ¨**
